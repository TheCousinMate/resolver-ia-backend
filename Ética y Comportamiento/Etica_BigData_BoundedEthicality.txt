Article Big Data and Bounded Ethicality Yuval Feldman* Yotam Kaplan** Wrongdoing is ubiquitous. Media outlets constantly report an endless stream of deleterious human behavior, from sexual harassment and fraud in financial markets to corporate and political corruption. Recent developments in behavioral ethics research suggest that these ills will forever accompany human interaction due to the phenomenon of “bounded ethicality,” or people’s limited ability to conduct an objective and candid moral examination of their own actions. When evaluating the ethical implications of their behavior, individuals have been shown to be biased and to systematically underestimate or ignore the magnitude and effect of their own misconduct. Such findings have troubling implications from a law enforcement perspective. That is, if wrongdoers are able to convince themselves they are doing nothing wrong, how can regulators and policy makers ever successfully reduce or prevent misconduct? Essentially, recognizing the power of bounded ethicality reinforces the idea that destructive human behavior may be unavoidable, and that it may never be possible the systematic wrongdoing currently observed throughout society. to reduce In response to the challenges that bounded ethicality poses, this Article explores how using big data analytics contributes to curbing both ethical bias and the results of bounded ethicality. The paper is breaking new ground in being the first to explore the intersections between the growing literature on behavioral ethics, highlighting the concept of bounded law ethicality, and the scholarship and research on data-driven * Yuval Feldman, Mori Lazarof Professor of Legal Research, Bar-Ilan University Law School, PhD UC Berkeley. ** Yotam Kaplan, Assistant Professor, Bar-Ilan University Law School, S.J.D Harvard Law School. The paper was presented at the Private Law Consortium in Harvard Law School, the Compliance Net Conference in UC Irvine Law School, NYU Law & Economics Workshop, Bonn University Law & Economics Seminar, the ERCP Regulatory Governance Conference in the University of Lausanne, and the 2018 Law and Communities Conference at Bar-Ilan University Law School. We wish to thank Shahar Ayal, Omri Ben-Shahar, Bernard Black, Noam Gidron, Yehonatan Givati, Ehud Guttel, Katherine Litvak, Miriam Markowitz-Biton, Gideon Parchomovsky, Ariel Porat, Alex Raskolnikov, Henry Smith, and Benjamin Van Rooij for helpful comments and discussions, and Shani Wiersch for excellent research assistance. Big Data & Bounded Ethicality 1/1/2019 enforcement. We suggest that to combat bounded ethicality, regulators should use ethical nudges, regulatory interventions designed to improve ethical deliberation by potential wrongdoers. We show that the use of big data analytics is crucial for the successful deployment of such regulatory interventions, for several reasons. First, ethical nudges must be deployed in real time, when potential perpetrators are making their decisions regarding possibly unethical actions. Big data analysis can facilitate this type of timely regulatory response in its shift from ex post inquiry to ex ante prediction. By collecting and analyzing data on the antecedents of wrongdoing, big data analytics can enable regulators to respond at opportune moments and situations, rather than engage perpetrators ex post facto. Second, ethical nudges must be targeted rather than general. If individuals are nudged constantly, ethical nudges will their effectiveness due to the phenomenon of ethical numbing. By identifying the situations that breed unethicality and limiting nudges to those situations, big data analysis can ensure that people are not overexposed to ethical nudges, thereby maintaining their efficacy. lose Third, ethical nudges must also be tailored to the characteristics of the specific bias that is causing unethical behavior in each specific case. Using big data analytic, together with behavioral ethics insights, regulators can collect information that will indicate the nature of the ethical bias operating in specific instances of wrongdoing, and thus be able to deploy the appropriate regulatory response. In addition to presenting several other advantages of using big data analytics as part of the efforts to reduce bounded ethicality, this paper suggests a full menu of regulatory tools designed to improve moral deliberation and discusses the importance of big data analytics as a basis for their use. Our analysis calls for a reorientation of existing practices of data- driven law enforcement, to make it more suited for the regulation of bounded ethicality. We show that this reorientation is also necessary for reasons related to the legitimacy of data-driven law enforcement. Data- driven law enforcement currently adopts a personalized focus, attempting to identify individuals who are more likely to commit crimes. This approach is highly problematic, concerns and perpetuating discriminatory practices. raising privacy Conversely, the approach we advocate calls for a focus on situations, not individuals, as behavioral ethics studies show that bounded ethicality is primarily situation driven. Therefore, big data analytics should be used to identify situations that breed unethicality, thus shifting the focus to 1/1/2019 Feldman & Kaplan individuals more likely to act badly. This use of big data analytics is less harmful to individuals’ privacy, as it does not focus on personalizing legal treatments. Deterrence Theory Legitimacy Ethical Nudges INTRODUCTION I. BEHAVIORAL ETHICS AND BOUNDED ETHICALITY A. Bounded Rationality versus Bounded Ethicality B. The Cognitive Sources of Bounded Ethicality C. Experimental Evidence for Bounded Ethicality D. The Costs of Bounded Ethicality II. BOUNDED ETHICALITY AND LAW ENFORCEMENT A. Ethical Nudges and the New Regulatory Approach 1. 2. 3. B. The Challenges for Ethical Nudges 1. 2. 3. 4. 5. Real Time Responses Ethical Numbing Selecting Among Nudge Types The Scope of Regulation Willingness to be Nudged III. THE PROMISE OF BIG DATA REGULATION 13 16 21 24 26 30 31 36 38 40 42 46 50 Interpersonal Variation and Bounded Ethicality The Inadequacy of Personality Traits as Predictors of Unethicality 52 Personalizing Law Based on Demographic Information 55 58 A. The Existing Personalized Law Approach 1. 2. 3. B. The Proposed Situational Law Paradigm 1. 2. A. Predictive Regulation B. Targeted Regulation C. Tailored Regulation D. Integrated Datasets E. The Strength of Data-Driven Interventions The Mechanics of Situational Regulation The Advantages of Situational Regulation IV. REORIENTING BIG DATA LAW ENFORCEMENT CONCLUSION INTRODUCTION Behavioral ethics is an emerging field of scientific research that studies the cognitive aspects of ethical decision-making.1 Behavioral ethics 1 For a recent review of behavioral ethics literature, see Francesca Gino, Understanding Ordinary Unethical Behavior: Why People Who Value Morality Act Immorally, 3 CURR. OPINION BEHAV. SCI. 107, 107–8 (2015). Big Data & Bounded Ethicality 1/1/2019 research highlights the concept of bounded ethicality, referring to various biases that prevent people from making an objective and candid ethical deliberation.2 Since people tend to interpret reality in a self-serving way, they frequently are unable to fully recognize the harmfulness of their actions.3 Consequently, people do not generally think of themselves as bad people and do not think of their actions as morally corrupt, even when an objective evaluation would immediately reveal their conduct as immoral and harmful to others.4 Bounded ethicality is responsible for the persistent wrongdoing in all spheres of life. Behavioral ethics research shows that people value their own morality and will typically act unethically only if they can do so while still maintaining a positive self-image as moral individuals.5 Bounded ethicality means that people are often blind to their own misdeeds, and therefore find it easy to act unethically without experiencing guilt.6 In this way, bounded ethicality perpetuates widespread misconduct by a large proportion of people.7 This paper highlights the potential of big data analytics as a cure for transgressions that arise from people’s bounded ethicality. Of course, a total solution for the problem of bounded ethicality will probably never be available. Nonetheless, there is evidence that big data analytics has some promising features that make it especially suited to confronting the challenges highlighted in recent empirical works by behavioral ethics scholars. In exploring this possibility, this paper is the first to combine behavioral ethics research with the literature on big data law enforcement. The paper thus breaks new ground by connecting two important and trending fields of literature, and by offering novel possibilities for regulating and reducing the most common types of wrongdoing. 2 YUVAL FELDMAN, THE LAW OF GOOD PEOPLE: CHALLENGING STATES’ ABILITY TO REGULATE HUMAN BEHAVIOR 1 (2018) (“various psychological and social mechanisms […] prevent people from recognizing their wrongdoing and encourage them to feel as if they are far more moral, unbiased, and law abiding than they actually are”). 3 Id. at 152 (describing the concept of moral disengagement and common excuses perpetrators adopt to justify their own wrongdoing). 4 Anthony G. Greenwald & Mahzarin R. Banaji, Implicit Social Cognition: Attitudes, Self-Esteem, and Stereotypes, 102(1) PSYCHOL. REV. 4, 10-11 (1995). 5 Nina Mazar, On Amir & Dan Ariely, The Dishonesty of Honest People: A Theory of Self-Concept Maintenance, 45(6) J. MARKETING RESEARCH 633, 633 (2008) (offering the theory of self-concept maintenance, according to which “people behave dishonestly enough to profit but honestly enough to delude themselves of their own integrity”). 6 Id. at 634 (showing that “people can cheat while avoiding any negative self-signals that might affect their self-concept and thus avoid negatively updating their self-concept altogether”). 7 FELDMAN, supra note 2, at 1 (discussing the prevalence of misconduct by ordinary people in everyday situations). 1/1/2019 Feldman & Kaplan The motivation for our study lies in the realization that law enforcement practices must be reformed in light of behavioral ethics findings.8 Research in behavioral ethics reveals the centrality of bounded ethicality as the root cause of systematic and tenacious unethical behavior in all spheres of life. Thus, it has been shown that bounded ethicality is central to all major societal ills, ranging from sexual harassment9 and racial discrimination of employees10 to political corruption11 and systematic violations of consumer rights.12 Since wrongdoing is so often caused by people’s bounded ethical capabilities, a key aim of regulatory intervention should be to improve individuals’ moral deliberation.13 To illustrate this point, consider first the widespread phenomenon of sexual harassment. In the aftermath of the Me Too movement, it is now clearer than ever that sexual harassment is extremely common, often likened to an epidemic,14 with more than 80 percent of women in the United States reporting they have been the harassed.15 Research in behavioral ethics research shows that the bounded ethicality of harassers is a major cause of sexual harassment and its disturbing prevalence. Thus, harassers are too often able to convince themselves that they are not in fact harassing, but that their advances are welcomed,16 and that their behavior is 8 Id. at 88-104 (presenting the need for a new regulatory approach, designed to enhance ethical decision-making). 9 Ann E. Tenbrunsel, McKenzie R. Rees & Kristina A. Diekmann, Sexual Harassment in Academia: Ethical Climates and Bounded Ethicality, 70(1) ANN. REV. PSYCHOL. 245, 245-6 (2019). 10 Linda Hamilton Krieger, The Content of our Categories: A Cognitive Bias Approach to Discrimination and Equal Employment Opportunity, 47 STAN. L. REV. 1161, 1164 (1995) (showing that most discriminatory decisions are made with limited rather than full awareness). 11 FELDMAN, supra note 2, at 190. 12 Alain Cohn, Ernst Fehr & Michel André Maréchal, Business Culture and Dishonesty in the Banking Industry, 516(7529) NATURE 86, 86 (2014). 13 FELDMAN, supra note 2, at 88. 14 Tenbrunsel et al., supra note 9, at 245–6 (2019); David Batty, Sally Weale & Caroline Bannock, Sexual Harassment at ‘Epidemic levels’ in UK Universities,” THE GUARDIAN 2017) harassment-epidemic. (March 5, 15 THE FACTS BEHIND THE #METOO MOVEMENT: A NATIONAL STUDY ON SEXUAL HARASSMENT AND ASSAULT (February 2018), content/uploads/2018/01/Full-Report-2018-National-Study-on-Sexual-Harassment-and- Assault.pdf. 16 Jonathan W. Kunstman & Jon K. Maner, Sexual Over-Perception: Power, Mating Motives, and Biases in Social Judgment, 100 J. PERSONALITY & SOC. PSYCHOL. 282, 282 (2010) (finding that some men tend to systematically overestimate the sexual interest others have in them). Big Data & Bounded Ethicality 1/1/2019 harmless,17 or socially acceptable.18 Of course, perpetrators do not usually think that sexual harassment itself is accepted; rather, their biased ethical thinking allows them to ignore the fact that their own acts constitute harassment. This is the mechanism by which bounded ethicality perpetuates sexual harassment as a social reality.19 To fight sexual harassment effectively, policy makers must find ways to make it harder for perpetrators to excuse or dismiss it.20 Bounded ethicality is similarly central to misconduct in the commercial sphere, with misrepresentation by financial advisors being a prime example.21 Financial advisors provide unsuitable advice, misrepresent facts, and engage in unauthorized activity.22 Such behaviors are responsible for constant losses for investors, not to mention occasional calamities, such as the Enron scandal,23 or the 2008 financial collapse.24 In the United States, more than 650,000 financial advisors manage over $30 trillion in private assets for American families.25 The frequency of misconduct by those 17 Maria Rotundo, Dung H. Nguyen & Paul R. Sackett, A Meta-Analytic Review of Gender Differences in Perceptions of Sexual Harassment, 86 J. APPLIED PSYCHOL. 914 (2001) (The authors report that women, as compared to man, perceive many more behaviors as harassing; this means potential perpetrators often fail to recognize the harmfulness of their behavior). 18 Tenbrunsel et al., supra note 9, at 255 (“harassers who experience ethical fading may be blind to the ethical dimensions of their actions, leading to behavior that they consider benign but that is in fact sexual harassment”). 19 Marisela Huerta, Lilia M. Corina, Joyce S. Pan, Cynthia M. Torges & Vicki J. Magley, Sex and Power in the Academy: Modeling Sexual Harassment in the Lives of College Women, 32 PERSONALITY & SOC. PSYCHOL. BULLETIN 616, 616 (2006) (describing the effect of sexual harassment based on a data from 1,455 college women). 20 Tenbrunsel et al., supra note 9, at 255. 21 Alain Cohn, Ernst Fehr & Michel André Maréchal, Business Culture and Dishonesty in the Banking Industry, 516(7529) NATURE 86, 86 (2014). 22 Mark Egan, Gregor Matvos & Amit Seru, The Market for Financial Adviser Misconduct, J. POL. ECONOMY 1, 1 (forthcoming 2019). For similar work in the context of auditing, see Max H. Bazerman, George Loewenstein, & Don A. Moore, Why Good Accountants do Bad Audits, 80(11) HARV. BUS. REV. 96 (2002). 23 See Jeffrey N. Gordon, What Enron Means for the Management and Control of the Modern Business Corporation: Some Initial Reflections, 69 (3) U. CHI. L. REV. 1233, 1233–34 (2002) (describing the scandal, in which the company falsely reported earnings in the hundreds of millions over a period of four years, leading to its collapse and to major losses for shareholders and employees; at the same time, executives sold their stock while publicly restating their faith in the company). 24 See Robert Grosse, The global financial crisis—Market misconduct and regulation from a behavioral view, 21 RESEARCH IN INT’L BUS. & FIN. 387, 387 (2017) (exploring the behavioral causes of the financial crisis and the regulatory means supposed to circumvent it); Edward J. Schoen, The 2007–2009 Financial Crisis: An Erosion of Ethics: A Case Study, 146(4) J. BUS. ETHICS 805, 806 (2017) (counting “disgraceful banking practices” among the main reasons for the crisis). 25 Andrew Coen, Investable Assets Hit $33.5 Trillion, FINANCIAL PLANNING (Nov 13 1/1/2019 Feldman & Kaplan financial advisors is staggering, as many current employees of financial institutions and firms are repeat offenders who have been previously accused of violating consumers’ rights.26 Bounded ethicality is a central cause for the ubiquity of misconduct by financial advisors.27 By the nature of their occupation, financial advisors provide their clients with highly speculative information; and it has been shown that people find it much easier to persuade themselves of their own truthfulness when the information they are presenting is highly uncertain.28 Financial advisors also operate under vague and general legal standards,29 and studies show that this ambiguity contributes to the ability of financial advisors to excuse or ignore their own misconduct.30 Similarly, it has been demonstrated that people find it much easier to convince themselves they are not committing a wrong when the definition of a wrong is unclear.31 Financial advisors, like many employees, also often operate under distorted norms of professionalism, putting the interests of the organization above anything else, including the legitimate interests of other parties.32 Similarly, studies have found that people avoid experiencing guilt when they do not feel their 2015) financial-planning.com/news/investable-assets-hit-335-trillion. 26 Mark Egan, Gregor Matvos & Amit Seru, The Market for Financial Adviser Misconduct, J. POL. ECONOMY 1, 1 (forthcoming 2019). 27 Yuval Feldman, Using Behavioral Ethics to Curb Organizational Misconduct, 3(2) BEHAVIORAL SCIENCE AND POLICY SPECIAL VOLUME ON CORRUPTION (2018) Available at SSRN: 28 Yuval Feldman & Doron Teichman, Are All Legal Probabilities Created Equal? 84 N.Y.U. L. REV. 980 (2009) (studying the effect of ambiguous legal standards on deterrence and compliance). 29 Investment advisors typically operate under a fiduciary duty, understood as an obligation to give priority to their customers’ interests over their own. For a theoretical analysis of fiduciary duties, see Robert H Sitkoff, The Economic Structure of Fiduciary Law, 91 B.U.L. REV. (2011). For an analysis of fiduciary duties in the corporate context, see Oliver Hart, An Economist's View of Fiduciary Duty, 43 U. TORONTO L.J. (1993). In the case of brokers, who are not legally considered investment advisors, the legal standards are even murkier. Currently, the law has yet to precisely define the legal standard under which brokers operate, and it is not even clear if this standard is equivalent to a fiduciary duty or to some other, lesser, form of duty toward their clients (Arthur B. Laby, Implementing Regulatory Harmonization at the SEC, 30 REV. BANKING & FIN. L. (2010)). 30 Behavioral ethics research usually discusses this issue in terms of the paradigm of moral wiggle room: see Jason Dana, Roberto A. Weber & Jason Xi Kuang, Exploiting Moral Wiggle Room: Experiments Demonstrating an Illusory Preference for Fairness, 33(1) ECON. THEORY 67 (2007). 31 For a theoretical development of this point, see Yuval Feldman & Henry E. Smith. Behavioral Equity, 170(1) J. INSTITUTIONAL & THEORETICAL ECON. 137 (2014). For empirical evidence for the effect of legal ambiguity, see Constantine Boussalis, Yuval Feldman & Henry E. Smith, Experimental Analysis of the Effect of Standards on Compliance and Performance, 12(2) REGULATION & GOVERNANCE 277 (2018). 32 Id. at 2-3. Big Data & Bounded Ethicality 1/1/2019 wrong benefited them personally, but was rather committed in the name of an organization.33 Finally, it has been shown that people find it much easier to excuse and justify a wrong against an unknown and unrecognized target,34 and financial advisors often work with clients they do not know, or have never met in person. The cumulative effect of these factors helps explain the ubiquity of unethicality in the financial sector. Thus, to battle misconduct in financial markets, regulators must account for bounded ethicality and find ways to remove or reduce ethical blind spots.35 Finally, consider the effects of bounded ethicality on the behavior of elected officials, purportedly required to consider the public interest above their own self-interest.36 A recent OECD report declared bounded ethicality as one of the major causes of political corruption, and suggested that behavioral ethics research should be used to battle corruption worldwide.37 Research indicates that bounded ethicality is a central cause of political corruption, as officials are often unable to adequately distinguish their own narrow interests from the best interests of their constituencies.38 Thus, for example, a politician will become convinced that he or she is voting for a certain bill because of the persuasive argument of a lobbyist, rather than the prospect of future financial support from the interest group represented by that same lobbyist. Public servants, like all people, are often guided by mixed motives, acting for both legitimate and illegitimate reasons. Under such circumstances, behavioral ethics research shows that people are influenced by an objectivity bias,39 which causes people to mistakenly 33 Scott S. Wiltermuth, Cheating More When the Spoils Are Split, 115(2) ORGANIZATIONAL BEHAVIOR & HUMAN DECISION PROCESSES 157 (2011) (providing empirical evidence that people cheat more when some of the “spoils” will benefit others); Julian Conrads, Bernd Irlenbusch, Rainer Rilke & Gari Walkowitz, Lying and Team Incentives, 34 J. ECON. PSYCHOL. 1 (2013) (showing that group incentive schemes lead people to cheat more, compared to individual incentive schemes). 34 Amitai Amir, Tehila Kogut & Yoella Bereby-Meyer, Careful Cheating: People Cheat Groups Rather Than Individuals, 7 FRONTIERS IN PSYCHOL. 371, 371 (2016). 35 MAX H. BAZERMAN & ANN E. TENBRUNSEL, BLIND SPOTS: WHY WE FAIL TO DO WHAT’S RIGHT AND WHAT TO DO ABOUT IT 1–3 (2011) (explaining the concept of ethical blind spots, situations in which ethical deliberation is hindered and unethicality therefore proliferates). 36 Eyal Zamir and Raanan Sulitzeanu-Kenan, Explaining Self-Interested Behavior of Public-Spirited Policymakers. PUB. ADMIN. REV. (2017). 37 OECD, Behavioural Insights for Public Integrity: Harnessing the Human Factor to Counter Corruption, OECD PUB. GOVERNANCE REVIEWS (2018), available at Paris, (suggesting that bounded ethicality is one of the main reasons for corruption and offering ways to use behavioral insights to battle corruption). 38 FELDMAN, supra note 2, at 190. 39 Don A. Moore & George Loewenstein, Self-Interest, Automaticity, and the Psychology of Conflict of Interest, 17(2) SOC. JUST. RESEARCH 189, 189 (2004). 1/1/2019 Feldman & Kaplan attribute their decisions to legitimate motivations and to downplay the effect of self-interest on their decisions.40 To effectually reduce corruption, policy makers must understand its cognitive sources and act to overcome them. More generally, our perception of regulation and law enforcement must change to accommodate behavioral ethics findings and the concept of bounded ethicality. Since people’s inability to conduct an objective and candid ethical evaluation is a major source of illegal and immoral behavior,41 one of the main aims of legal policy must be to improve ethical deliberation by potential wrongdoers.42 Regulators should therefore strive to engage directly with perpetrators’ level of ethical awareness, and act to make it more difficult for people to dismiss or ignore the harmfulness of their actions.43 This means regulators should aspire to target perpetrators’ awareness in real time, when wrongdoing is being committed.44 Thus, we propose the use of ethical nudges, regulatory tools that encourage ethical deliberation by guiding wrongdoers towards a better understanding of their own behaviors.45 For example, in the case of misrepresentation by financial advisors, electronic messages may alert representatives to reconsider their statements when they contain exaggerated content. As we describe herein,46 similar tools are already being implemented in some contexts.47 This proposed change in the perception of law enforcement, aimed at regulating bounded ethicality, calls for a shift in emphasis in current regulatory policies that are not structured explicitly with this goal in mind.48 40 Dolly Chugh, Max H. Bazerman, & Mahzarin R. Banaji, Bounded Ethicality as a Psychological Barrier to Recognizing Conflicts of Interest, in CONFLICTS OF INTEREST: CHALLENGES AND SOLUTIONS IN BUSINESS, LAW, MEDICINE, AND PUBLIC POLICY 74, 74 (Don. A. Moore, Daylian M. Cain, George Loewenstein & Max H. Bazeman eds., 2005) (explaining that people view themselves as more objective than others and are therefore unable to see themselves as corrupt); Emily Pronin, Thomas Gilovich & Lee Ross, Objectivity in the Eye of the Beholder: Divergent Perceptions of Bias in Self Versus Others, 111(3) PSYCHOL. REV. 781, 781–2 (2004). 41 FELDMAN, supra note 2, at 1. 42 Id. at 88–104. 43 Mazar et al., supra note 5, at 633 (showing that people’s behavior can be improved if interventions make it harder for them to justify their unethicality to themselves). 44 See BAZERMAN & TENBRUNSEL, supra note 35, at 1–3 (explaining that unethicality is predictable based on situational factors and that it is therefore possible to identify instances in which unethical behavior is likely to occur). 45 See infra, subsection II.A.3; for more on ethical nudges, see FELDMAN, supra note 2, at 198. 46 See infra, subsections II.A.3, IIB.3. 47 Todd Haugh, Nudging Corporate Compliance, 54 AM. BUS. L.J. 683, 712, 736 (2017); Portia Crowe, JP Morgan Is Working on a New Employee Surveillance Program, BUS. INSIDER (Apr. 8, 2015, 9:52 AM), employee-surveillanceprogram-2015–4. 48 FELDMAN, supra note 2, at 10, 32. Big Data & Bounded Ethicality 1/1/2019 This shift also presents several challenges, as new tools and abilities not traditionally considered part of the regulatory toolkit are required for regulating bounded ethicality. We discuss these challenges here and then proceed to highlight the solutions big data analytics offer. First, to curb bounded ethicality, regulators must be able to initiate interventions in real time, when perpetrators are making their ethical, or unethical, decisions.49 If misconduct originates with individuals’ bounded ethicality, regulators must engage with people’s awareness to prompt improved ethical deliberation by perpetrators.50 To do that, regulators need to be able to predict unethicality in order to deploy ethical nudges at the time that ethical decisions are actually being made. Second, regulatory interventions must be targeted and specific rather than broad and general.51 Behavioral ethics research suggests that it would be nearly impossible to generate a general improvement in people’s ethical deliberation capabilities.52 Just as we cannot expect to solve the problems of bounded rationality and make people generally more rational, we also cannot expect to be able to solve the problems of bounded ethicality and simply produce generally more competent ethical thinkers. Instead, behavioral ethics research suggests we can improve ethical decision-making in specific instances by applying appropriate targeted interventions.53 This means that ethical nudges, designed to improve deliberation, must be presented only if and when they are truly needed. If everyone constantly encounters ethical nudges, such nudges would lose their meaning and impact. Typically, from an awareness perspective, ethical nudges must stand out to counter the phenomenon of ethical numbing, referring to individuals’ decline in moral awareness in response to repetition and routine.54 Therefore, ethical nudges must be deployed carefully and sparingly, in a way that will maximize their impact on perpetrators' awareness. Third, regulatory interventions must be tailored; that is, sensitive to the 49 See infra, subsection II.B.1. 50 FELDMAN, supra note 2, at 10, 32. 51 See infra, subsection II.B.2. 52 Dolly Chugh & Mary C. Kern, A Dynamic and Cyclical Model of Bounded Ethicality, 36 RESEARCH IN ORGANIZATIONAL BEHAVIOR 85, 85 (2016). 53 Lisa L. Shu, Francesca Gino & Max H. Bazerman, Dishonest Deed, Clear Conscience: When Cheating Leads to Moral Disengagement and Motivated Forgetting, 37(3) PERSONALITY & SOC. PSYCHOL. BULLETIN 330, 344 (2011). 54 Albert Bandura, Moral Disengagement in the Perpetration of Inhumanities, 3(3) PERSONALITY & SOC. PSYCHOL. REV. 193, 204 (1999); Ann E. Tenbrunsel & David M. Messick, Ethical Fading: The Role of Self-Deception in Unethical Behavior, 17(2) SOC. JUST. RESEARCH 223, 228 (2004) (referring to the “psychological numbing that comes from repetition”). 1/1/2019 Feldman & Kaplan characteristics of specific cases.55 Behavioral ethics research shows that unethicality is generated by a variety of different biases that allow individuals to excuse, ignore, or justify their misconduct. Each type of bias calls for a different regulatory response in order to improve ethical deliberation. To achieve this goal of improving ethical decision-making, regulators must be able to choose an ethical nudge that would help reduce the specific ethical bias that is causing unethical behavior in each specific case. Fourth, behavioral ethics research shows that, in some situations, a great majority of people will choose to lie and cheat.56 Consequently, regulators can no longer focus their attention exclusively on abnormal cases and extreme lawbreakers, but must be able to regulate a much larger percentage of people.57 Fifth, ethical nudges face a unique challenge, as they seek to prompt individuals to behave morally and consider the welfare of others. In contrast, traditional nudges help people act more effectively in their own favor.58 This motivational difference between traditional and ethical nudges means that individuals do not always have the incentive to be ethically nudged, and ethical nudges must be particularly effective in order to work.59 These challenges make it particularly difficult to mitigate the effects of bounded ethicality. We argue that the key features of big data analytics make it a particularly promising tool for overcoming these issues. Big data analytics can be used to identify and characterize the antecedents of unethical behavior, and thus guide policy makers regarding the most appropriate regulatory responses. Through the integration and analysis of existing databases, policy makers and law enforcers can identify more accurately the conditions under which unethicality flourishes. By mining these datasets for patterns, we can learn to describe, in a much more finely calibrated way, the specific characteristics of prevalent wrongdoing and identify the situations in which regulation will be most effective. This will enable regulators to identify those specific situations in which targeting transgressors' awareness and triggering moral deliberation will be most effective, and then advance the appropriate regulatory response. As we show, such a regulatory scheme can provide answers to the challenges of regulating bounded ethicality. 55 See infra, subsection II.B.3. 56 DAN ARIELY & SIMON JONES, THE (HONEST) TRUTH ABOUT DISHONESTY: HOW WE LIE TO EVERYONE, ESPECIALLY OURSELVES (2012) (the aggregate results of the experiments and findings presented by the authors emphasizes how widespread unethicality actually is). 57 See infra, subsection II.B.4. 58 FELDMAN, supra note 2, at 198–9. 59 See infra, subsection II.B.5. Big Data & Bounded Ethicality 1/1/2019 First, data-driven law enforcement marks a shift from ex post inquiry to ax ante prediction.60 That is, using big amounts of data, regulators and law enforcers are now increasingly able to anticipate unethical behavior and recognize its antecedents. This capacity is crucial if regulators are to be able to deploy ethical nudges in real time, and thus influence perpetrators’ ethical deliberation as decisions are being made.61 Second, by using big data analytics, regulators can minimize their use of ethical nudges, and deploy them only if and when they are needed. This will enable the use of targeted regulatory interventions, and help avoid the problem of ethical numbing and the danger that ethical nudges will lose their effectiveness if overused.62 Third, big data analysis can help ascertain in great detail the characteristics of each specific instance of wrongdoing. This can help identify the behavioral mechanism responsible for the unethical conduct, and allow regulators to apply the most suitable type of regulatory intervention in each case. Thus, regulation driven by big data analysis can the specific behavioral facilitate characteristics of each violation.63 regulation, sensitive tailored to Fourth, big data in law enforcement signifies a shift from data focused on repeat offenders and extreme cases to data that covers the population as a law whole, enforcement authorities.64 This comprehensive characteristic of big data is useful for the goal of curbing bounded ethicality, as wrongdoing is committed by a substantial proportion of people.65 those who have not previously encountered including Fifth, research shows that the use of big data analysis can help make existing regulatory means significantly more potent, as the abundance of information facilitates an accurate and effective intervention.66 This can provide ethical nudges the extra kick necessary to induce individuals to consider the interests of others, rather than their own, as is the case with traditional nudges.67 Part I of this Article provides an introduction to behavioral ethics and explains the concepts of bounded ethicality. This Part clarifies the main 60 Andrew G. Ferguson, Big Data and Predictive Reasonable Suspicion, 63(2) U. PA. L. REV. 327, 369 (2015). 61 See infra, section III.A. 62 See infra, section III.B. 63 See infra, section III.C. 64 Sarah Brayne, Big Data Surveillance: The Case of Policing, 82(5) L. & SOC’Y REV. 977, 992 (2017). 65 See infra, section III.D. 66 Sarah Brayne, Big Data Surveillance: The Case of Policing, 82(5) L. & SOC’Y REV. 977, 981–2 (2017). 67 See infra, section III.E. 1/1/2019 Feldman & Kaplan findings of behavioral ethics research and differentiates this field from other branches of behavioral science, such as behavioral law and economics. This Part also elaborates on the types of bounded ethicality described in behavioral ethics research, and on its heavy social costs. Part II highlights the relevance of behavioral ethics findings for law enforcement and regulation. Its aim is to demonstrate the need for a new regulatory approach that more explicitly targets the ethical awareness of potential perpetrators. This Part surveys prevailing theories of regulation and law enforcement and reveals their inadequacies in light of behavioral ethics findings. Mainly, existing regulatory paradigms that emphasize such concepts as deterrence and legitimacy fall short once we recognize the ability of perpetrators to ignore or justify their own unethical behavior. This Part details the challenges that behavioral ethics presents for law enforcement, and situates the problem of improving behavior in a world of ethically bounded actors. Part III continues by introducing the solution of data-driven regulation, and highlights its advantages in the context of each of the regulatory challenges presented in Part II. Part III surveys existing practices of data-driven law enforcement, and shows how these existing elements can be tweaked to regulate bounded ethicality in a more effective manner. Our proposal is based on combining the literature and practice of data-driven law enforcement with behavioral ethics research and its empirical findings. Part IV considers some of the main challenges for our proposal, especially in terms of privacy and constitutionality. We argue for a reorientation of current data-driven law enforcement practices. In particular, we show that regulation based on big data analysis should shift from its current focus on individualization and personalization, and adopt instead a situational focus. This will make big data law enforcement more effective in reducing bounded ethicality, and also more legitimate and less harmful with respect to individuals’ privacy. These four sections are followed by a short conclusion. I. BEHAVIORAL ETHICS AND BOUNDED ETHICALITY Recently, there has been a dramatic increase in the study and conceptualization of non-deliberative decision-making. Extensive research has generated competing paradigms describing various aspects of behavior that are not regulated with full consciousness.68 The prominence of scholars far beyond the sphere of academia, such as Daniel Kahneman, who won the 68 Jonathan Haidt, The Emotional Dog and its Rational Tail: A Social Intuitionist Approach to Moral Judgment, 108(4) PSYCHOL. REV. 814, 814–15 (2001) (arguing that moral reasoning is typically the result of quick, automatic evaluation and that rational justifications are only made after the fact). Big Data & Bounded Ethicality 1/1/2019 2002 Nobel Prize, and Eldar Shafir in psychology, Richard Thaler in economics, Cass Sunstein and Dan Kahan in law, and Dan Ariely and Max Bazerman in management, demonstrates the broad acceptance of the importance of intuitive and non-deliberative aspects of human choice and behavior. One paradigm that has been popularized by Kahneman’s book, Thinking, Fast and Slow, is the existence of two systems of reasoning.69 The dual-reasoning system, which has been the subject of thousands of papers70 and many books,71 differentiates between System 1, an automatic, intuitive, and mostly unconscious process, and System 2, a controlled and deliberative process.72 The recognition of the significant role of automaticity in decision-making has played an important role in the emergence of behavioral economics73 and subsequently behavioral law and economics.74 More recently, these insights have also been central to the development of the field of behavioral ethics75 and to its introduction into legal scholarship.76 A. Bounded Rationality versus Bounded Ethicality Both behavioral ethics and behavioral law and economics address the role of self-interest in decision-making. However, whereas behavioral ethics examines how people are driven by self-interest even when that compels them to act unethically, behavioral law and economics offers an explanation for why people do not make decisions that are in their best interests.77 69 DANIEL KAHNEMAN, THINKING, FAST AND SLOW (2011). 70 Cass R. Sunstein, Behavioral Law and Economics: A Progress Report. 1 AM. L.ECON. REV. 115, 115 (1999) (“the last decade has seen an outpouring of work in behavioral law and economics; in the last few years, the outpouring has become a flood”); Donald C. Langevoort, Behavioral Theories of Judgment and Decision Making in Legal Scholarship: A Literature Review. 51 VAND. L. REV. 1499, 1499 (1998). 71 See Doron Teichman & Eyal Zamir, Judicial Decisionmaking: A Behavioral Perspective, in THE OXFORD HANDBOOK OF BEHAVIORAL ECONOMICS AND THE LAW (Doron Teichman & Eyal Zamir eds., 2014). 72 This paradigm has also been criticized by scholars, see Arie W. Kruglanski & Gerd Gigerenzer, Intuitive and Deliberate Judgments Are Based on Common Principles 118(1) PSYCHOL. REV. 97, 98 (2011) (surveying some of the literature criticizing the “dual model” which separates intuitive from deliberative judgment). 73 Russell B. Korobkin & Thomas S. Ulen, Law and Behavioral Science: Removing the Rationality Assumption from Law and Economics, 88 CAL. L. REV. 1051, 1075 (2000) (the authors survey the deep impact of the concepts of bounded rationality on legal scholarship). 74 Sunstein, supra note 70, at 117–121. 75 Gino, supra note 1. 76 FELDMAN, supra note 2. 77 Yuval Feldman, Behavioral Ethics Meets Behavioral Law and Economics, in THE OXFORD HANDBOOK OF BEHAVIORAL ECONOMICS AND THE LAW (Doron Teichman & Eyal Zamir eds., 2014) (comparing the concepts of bounded rationality and bounded 1/1/2019 Feldman & Kaplan Behavioral law and economics proposes the bounded rationality argument that because of information deficiencies, cognitive limitations, and time constraints, individuals fail to make rational decisions. As a result, people are not capable of making decisions to enhance their own welfare. In contrast, behavioral ethics proposes the concept of bounded ethicality, which focuses on people’s inability to recognize their own moral faults.78 Bounded ethicality clouds individuals’ judgement and prevents them from seeing how their own self-interest is subconsciously driving their actions and leading them towards unethical decisions. To illustrate the difference between these two concepts, consider an interaction between a financial advisor and a client. According to the concept of bounded rationality, the client might have different biases that will prevent him or her from accurately assessing the value of the product offered. In effect, the clients’ cognitive limitations hinder their ability to make decisions that would best serve their long-term self-interest. Conversely, bounded ethicality addresses the actions of the advisor and the mechanisms that limit the advisor’s ability to realize he or she is deceiving the client. Here, cognitive limitations sabotage the advisor’s ability to recognize that self-interest is preventing him or her from acting in an objective and professional way. Behavioral law and economics and behavioral ethics can thus be understood as studying opposing archetypes of cognitive limitations related to self-interest. Behavioral law and economics studies the ways in which our cognitive limitations hinder our ability to promote our own self-interest, while behavioral ethics is concerned with the power of self-interest to hinder our ability to engage in candid ethical deliberation. Behavioral ethics thus calls for reorienting behavioral analysis as applied to the law. It shifts the focus from whether people are able to act rationally in their own self-interest to whether they understand that they are at fault, whether their behavior can be modified, and whether something in the situation has affected their ability to recognize their wrongdoing. Understanding these processes of decision-making and how they affect questions of motivation, autonomy, and responsibility, rather than attempting to lead individuals towards their personal optimal outcome, is at the core of this new behavioral analysis of law. In our view, behavioral insights should inform efforts by policy makers to improve people’s ethical behavior, and not only their ability to make decision that benefit themselves. To this end, the introduction of ethical nudges offers a crucial refinement of the development of legal tools introduced by Thaler and ethicality, especially with relation to self-interest). 78 Mary C. Kern & Dolly Chugh, Bounded Ethicality: The Perils of Loss Framing 20(3) PSYCHOL. SCI. 378, 381–3 (2009). Big Data & Bounded Ethicality 1/1/2019 Sunstein,79 by refining the use of nudge tactics to improve ethical deliberation, rather than support the calculated pursuit of self-interest.80 B. The Cognitive Sources of Bounded Ethicality Behavioral ethics literature describes several mechanisms of bounded ethicality. First, bounded ethicality can lead individuals to ignore their own misconduct, or fail to recognize it as harmful. People's ethical judgement can be bounded in the sense that biased thinking prevents them from noticing their own unethicality. For example, this can result from motivated reasoning, a process by which individuals ignore some facts and emphasize others in a way that helps them support a perception of a moral self.81 This concept highlights the various ways by which self-interest unconsciously shapes people's understanding of reality, as individuals tend to interpret situations in ways that serve them best.82 Thus, through motivated reasoning, wrongdoers can interpret situations in a way that eliminates ethical dilemmas. Consequently, perpetrators often adopt a biased perception of reality their own wrongdoing.83 them from seeing that prevents Second, biased thinking can lead individuals to excuse and justify their own wrongs rather than ignore them. A central concept here is moral disengagement, or the habit of finding ways to excuse unethical conduct, even when the perpetrator is conscious of it.84 Behavioral ethics research describes a host of such tendencies, as bounded ethicality can lead perpetrators to justify misconduct through excuses such as “he had it coming” or “it would have happened even if I hadn’t been there.” Similarly, wrongdoers also engage in moral licensing, which relies on their positive self-image as ethical individuals to justify minor deviations from ethical conduct. The observation of Greenvald and Banaji on the power of implicit judgement is particularly relevant in this context: because people love 79 RICHARD H. THALER & CASS R. SUNSTEIN, NUDGE: IMPROVING DECISIONS ABOUT HEALTH, WEALTH, AND HAPPINESS (2008) (famously proposing the “nudge approach,” aiming to affect choice without limiting freedom). 80 FELDMAN, supra note 2, at 199. 81 Ziva Kunda, The Case for Motivated Reasoning, 108(3) PSYCHOLOGICAL BULLETIN, 480, 480 (1990) (“there is considerable evidence that people are more likely to arrive at conclusions that they want to arrive at, but their ability to do so is constrained by their ability to construct seemingly reasonable justifications for these conclusions”). 82Id.; Anna C. Merritt, Daniel A. Effron, & Benoît Monin, Moral Self-Licensing: When Being Good Frees Us to Be Bad, 4(5) SOC. PERS. PSYCH. COMPASS 344 (2010) (showing that individuals can use past good deeds to justify future violations of moral norms). 83 Kunda, supra note 81, at 480. 84 Bandura, supra note 54, at 204; Tenbrunsel & Messick, supra note 54, at 228. 1/1/2019 Feldman & Kaplan themselves, they have difficulty admitting, even to themselves, that they have behaved immorally.85 More generally, bounded ethicality is supported by people's tendencies to overestimate their own ability to remain impartial and to accurately assess the nature of their actions and motives.86 As a result, they will often believe they are acting more ethically than they actually are.87 Chugh, Bazerman and Banaji attribute such behaviors to an illusion of objectivity, which causes people to view themselves as more objective in comparison to others.88 This illusion hinders individuals' ability to recognize their lapses into corrupt and immoral behaviors. These psychological mechanisms not only amplify the effect of self-interest but also tend to limit people’s awareness of the role of self-interest in determining their behavior, thereby widening the gap between people’s actual behavior and their evaluation of its ethicality.89 Moore et al. demonstrate that people often truly believe their own biased judgements and thereby fail to recognize that their behavior is problematic.90 Gino and colleagues advance a similar view, showing that the level of control needed to behave ethically is much higher than that required to act unethically.91 Such mechanisms allow individuals who value themselves as moral people to routinely engage in immoral behavior that is not accompanied by malice.92 Importantly, individuals cannot ignore or justify any and all wrongs. Therefore, they will act unethically, but only in ways for which they can find reasonable justifications.93 Many behavioral ethics findings suggest a strong link between ethical blind spots and automated cognitive processes.94 That is, bounded ethicality 85 Greenwald & Banaji, supra note 4, at 10–11. 86 Ovul Sezer, Francesca Gino & Max H. Bazerman, Ethical blind spots: Explaining unintentional unethical behavior, 6 CURR. OPINION SCI. 77, 77 (2005). 87 Chugh, Bazerman & Banaji, supra note 40, at 74. 88 Id. 89 Guy Hochman, Andreas Glöckner, Susann Fiedler & Shahar Ayal, “I Can See it in Your Eyes”: Biased Processing and Increased Arousal in Dishonest Responses, 29(2–3) J. BEHAVIORAL DECISION MAKING 322 (2016). 90 Don A. Moore, Lloyd Tanlu & Max H. Bazerman, Conflict of Interest and the Intrusion of Bias, 5(1) JUDGMENT AND DECISION MAKING 37 (2010) (the authors suggest that individuals' true judgments can be discerned by rewarding participants for being accurate in their predictions). 91 Francesca Gino, Maurice E. Schweitzer, Nicole L. Mead & Dan Ariely, Unable to Resist Temptation: How Self-Control Depletion Promotes Unethical Behavior, 115(2) ORGANIZATIONAL BEHAVIOR AND HUMAN DECISION PROCESSES, 191, 192–3 (2011). 92 Gino, supra note 1, at 107. 93 Id. 485-6; Mazar et al., supra note 5, at 633 (“people behave dishonestly enough to profit but honestly enough to delude themselves of their own integrity”). 94 Haidt, supra note 68, at 814–15. Big Data & Bounded Ethicality 1/1/2019 is closely related to System 1 thinking and to intuitive decision-making processes. An important contribution to this line of research is offered in a recent work by Chugh & Kern.95 They focus on how automatic processes are all largely related to self-driven bounded ethicality processes.96 Along similar lines, Marquardt & Hoeger show that individuals make ethical decisions based on implicit rather than explicit attitudes.97 In examining the automatic system, Moore & Loewenstein have found that the effect of self- interest is automatic,98 and Epley & Caruso99 conclude that automatic processing leads to egocentric ethical interpretations.100 In a recent meta- analysis, Kobis and his colleagues found evidence of intuitive self-serving dishonesty, meaning that people are more likely to lie and cheat when making ethical decisions based on than on full deliberation.101 intuition rather C. Experimental Evidence for Bounded Ethicality The concept of bounded ethicality, as the term suggests, points to a strong link between unethical conduct and cognitive limitations and biases.102 The behavioral claim is that people truly believe their own biased ethical judgements, and are not always purposefully ignoring or justifying their own wrongs. That is, wrongdoing is not entirely conscious or calculated, but is often based on implicit judgement.103 For instance, an individual who prefers a specific conclusion, such as that he or she is not 95 Chugh & Kern, supra note 52, at 85. 96 Id. at 85; see also Chugh, Bazerman & Banaji, supra note 40, at 74. 97 Nicki Marquardt & Rainer Hoeger, The Effect of Implicit Moral Attitudes on Managerial Decision-Making: An Implicit Social Cognition Approach, 85(2) J. BUS. ETHICS 157, 159 (presenting evidence that many managers rely on intuitive evaluations rather than on rational judgment when faced with moral dilemmas). 98 Moore & Loewenstein, supra note 39, at 189 (“In many instances of conﬂict of interest, self-interest tends to operate via automatic processes whereas ethical and professional responsibilities operate via controlled processes”). 99 Nicholas Epley & Eugene M. Caruso, Egocentric Ethics, 17(2) SOCIAL JUSTICE RESEARCH 171 (2004). 100 Id. at 173; see also Moore & Loewenstein, supra note 39, at 195. 101 Nils C. Köbis, Bruno Verschuere, Yoella Bereby-Meyer, David Rand & Shaul Shalvi, Intuitive (Dis)honesty – A Meta-Analysis, 1 (working paper 2018). 102 Haidt, supra note 68, at 814–15. 103 For instance, in the employment discrimination arena, researchers have found that most discriminatory decisions are made implicitly rather than explicitly; see Linda Hamilton Krieger, The Content of our Categories: A Cognitive Bias Approach to Discrimination and Equal Employment Opportunity, 47 STAN. L. REV. 1161, 1164 (1995); Linda Hamilton Krieger & Susan T. Fiske, Behavioral Realism in Employment Discrimination Law: Implicit Bias and Disparate Treatment, 94(4) CAL. L. REV. 997, 1027–30 (2006). 1/1/2019 Feldman & Kaplan committing a wrong, will often selectively, but genuinely, remember and emphasize those elements that support this conclusion.104 This section briefly presents experimental evidence for these general claims to illustrate the concept of wrongdoing that is not fully calculated. First, consider findings regarding moral forgetting, reported in a three- stage experimental study by Lisa Shu, Francesca Gino, and Max Bazerman.105 At the first stage of this experiment, all participants were asked to memorize a university honor code, detailing, among other things, rules for appropriate behavior in taking a university exam.106 At the second stage, participants had to complete a series of short problem-solving tasks and report their results to an examiner in order to receive a monetary payment.107 Participants were paid according to the number of tasks they reported they had been able to perform. In reporting their results, participants were randomly assigned to one of two treatment groups. Participants in the first group were made to submit their task sheet forms when they asked for their payment. As a result, participants in this group had no opportunity to cheat, as the examiners could directly observe the quality of their performance.108 Participants in the second group were not required to submit their task sheets when asking for their payment, but were instead instructed to put those forms through a shredder. Participants in the second group were therefore given an opportunity to cheat, and, if they choose to do so, to report success rates that were higher than what they actually scored in order to receive a higher monetary payment.109 At the third and final stage of the research, all participants were asked to recall details of the honor code they had been asked to memorize at the first stage.110 The interesting finding of the research is that participants in the second group, who had been given an opportunity to cheat, displayed a strong effect of motivated forgetting. That is, they were less able to remember details of the honor code compared to participants who had not been given the opportunity to cheat.111 The findings of motivated forgetting suggest that people tend to forget facts that portray them in a negative light. Thus, to reduce the potential guilt associated with unethical behavior, people’s brains reduced their ability to remember rules that prohibited cheating. A similar concept is that of motivated seeing, explaining the effect of 104 Kunda, supra note 81, at 486. 105 Shu, Gino & Bazerman, supra note 53, at 339–41. 106 Id. at 339. 107 Id. 108 Id. at 340. 109 Id. 110 Id. at 341. 111 Id. Big Data & Bounded Ethicality 1/1/2019 self-interest on visual perception. In an experiment by Balcetis & Dunnig, the authors report findings suggesting that people’s wishes and preferences influence their processing of visual stimuli.112 In the study, participants were shown an ambiguous figure, such as a shape that could be reasonably interpreted as either the letter B or the number 13.113 Participants systematically tended to report seeing the interpretation that promised them a reward instead of a sanction.114 Using implicit measures of perception (e.g., eye tracking, lexical decision tasks) and experimental procedures, the authors were able to show that participants were genuinely aware only of the interpretation that favored their interests.115 These studies suggest that people not only tend to interpret information in a way that favors their interests, but that their mind completely blocks interpretations which are not serving their interests. Self-interest affects not only calculated decision- making, but also preconscious processing of visual stimuli. Self-interest can thus dictate the content that the visual system will present as a basis of conscious decision-making and perception can actually change to make it easier for people to cheat and act unethically.116 Finally, consider the study by Shalvi, Eldar, & Bereby-Meyer.117 In this experiment, participants were asked to roll a die under a cup, making the results of the roll known to the participant only. Participants were then asked to report the results of their rolls and were rewarded for higher rolls. The first group of participants was asked to roll the die once, and report the result to receive payment. Participants in the second group were instructed to roll the die twice, but were asked to report only the first roll.118 Arguably, there should be no difference in the payments to participants in the two groups, because they are all are equally rewarded for the results of just one die roll. However, the main finding of this experiment was that participants in the second group, that was allowed to roll twice, found it easier to falsely report higher rolls and thereby receive higher payments.119 This finding demonstrates that the decision to cheat is not fully calculated or rational, but is determined by environmental factors.120 Fully rationale and deliberate cheaters would have cheated equally under both experimental treatments, 112 Emily E. Balcetis & David Dunning, See What You Want to See: Motivational Influences on Visual Perception, 91(4) J. PERSONALITY & SOC. PSYCHOL. 612 (2006). 113 Id. at 615. 114 Id. 115 Id. at 617. 116 Id. at 617–8. 117 Shaul Shalvi, Ori Eldar & Yoella Bereby-Meyer, Honesty Requires Time (and Lack of Justifications), 23(10) PSYCHOL. SCI. 1264 (2012). 118 Id. at 1266. 119 Id. 120 Id. at 1269. 1/1/2019 Feldman & Kaplan and would have falsely reported to maximize their earnings. However, this was not the observed result of the experiment, as, in fact, participants in the first group cheated less, as they found it harder to lie regarding the result of their roll, while participants in the second group found it easier to lie about the result of their first roll when they could justify their lie based on their result in the second roll.121 This is because, while they might have been reluctant to say they had rolled a five when in reality they had rolled a two, when their second roll was in fact a five, it became much easier for them to rationalize reporting that they had rolled a five in the first throw. This finding again demonstrates the centrality of excuse and self-justification to wrongdoing and the divergence of these factors from the prediction of the rationale decision-making model. D. The Costs of Bounded Ethicality The social harms caused by people’s bounded ethicality are of unimaginable magnitude.122 Bounded ethicality leads to systematic and prevalent infractions and therefore to great aggregate harms. To illustrate this point, consider the case of simple employee theft.123 We all know that stealing is wrong. Yet, people find it surprisingly easy to justify stealing small items from work, even if they would never consider stealing cash worth the same amount. In this way, people’s bounded ethicality, or their inability to make an objective moral assessment of their actions, leads to a great deal of misconduct. In fact, studies indicate that nearly 50 percent of employees steal from their employer.124 Such misconduct is common, because employees are able to rationalize their wrongdoing as harmless or socially acceptable. Yet this supposedly mundane misdemeanor is in fact one of the most costly forms of crime, with losses for employers estimated at over $200 billion annually.125 The harm caused by employee theft 121 Id. at 1267. 122 Gino, supra note 1, at 107. 123 For an overview of the characteristics of this phenomenon and its main causes, see Richard C. Hollinger & John P. Clark, Deterrence in the Workplace: Perceived Certainty, Perceived Severity, and Employee Theft, 62(2) SOCIAL FORCES 398 (1983). 124 Peg Thoms, Paula Wolper, Kimberly S. Scott & Dave Jones, The Relationship between Immediate Turnover and Employee Theft in the Restaurant Industry, 15(4) J. BUS. & PSYCHOL. 561, 562 (2001); Brian P. Niehoff & Robert J. Paul, Causes of Employee Theft and Strategies that HR Managers Can Use for Prevention, 39(1) HUMAN RESOURCE MANAGEMENT 51, 51 (2000). 125 Brian P. Niehoff & Robert J. Paul, Causes of Employee Theft and Strategies that HR Managers Can Use for Prevention, 39(1) HUMAN RESOURCE MANAGEMENT 51, 51 (2000); For earlier estimates, see Lary K. Banning, Thievery on the Inside, 32 SECURITY MANAGEMENT 79, 80 (1988); Mark Lipman, Employee Theft: A $40 Billion Industry, 498 ANNALS AM. ACADEMY POL. & SOC. SCI. 51, 51 (1988). Big Data & Bounded Ethicality 1/1/2019 spreads far beyond employers, as it actually results in a 10 to 15 percent increase in the price of consumer goods, costing American families billions of dollars a year.126 Even more surprisingly, losses related to employee theft play a major part in the bankruptcies of between 30 to 50 percent of all insolvent organizations.127 The reason this form of crime is so costly is precisely because it appears relatively mundane. Because it is easy to excuse and justify, such misconduct is commonly practiced by the majority of ordinary normative people and therefore becomes extremely common. And because bounded ethicality is so common, its cumulative impact is devastating. This process of rationalizing what seem to be mundane acts leads to a paradoxical result: unethical acts that are perceived as effectively harmless are in fact the most harmful in the aggregate, because they become so common. Thus, for example, the practice of “wardrobing,” or buying an item, using it, and then returning it for a full refund, costs retailers $16 billion a year.128 Other “ordinary” unethical acts result in even higher costs. Accounting misconduct accounts for the loss of $40 billion a year, insurance fraud for $24 billion a year, intellectual property theft for $250 billion a year,129 and tax deception for over $300 billion a year.130 In contrast, the more “serious” crimes of car theft and burglary account for losses of $5.9 billion and $3.6 billion a year, respectively.131 This means that, in the aggregate, “ordinary” employee theft can be one hundred times more harmful, in dollar amounts, than “serious” crimes such as burglary. Only very few people can justify breaking into someone's home, but a great many can excuse stealing some paper from the office. Lab experiments show that bounded ethicality makes unethical conduct nearly universal under certain circumstances. 132 In a recent meta-analysis of studies involving more than 30,000 participants, researchers found that 126 RICHARD C. HOLLINGER & JOHN P. CLARK, THEFT BY EMPLOYEES 4 (1983). 127 Thoms et al., supra note 124, at 562; see David O. Friedrichs, Enron et al.: Paradigmatic White Collar Crime Cases for the New Century, 12 CRITICAL CRIMINOLOGY 113, 115 (2004). 128 Mazar et al., supra note 5, at 633. 129 For a review of the rationales used by people to justify file sharing, see Yuval Feldman & Janice Nadler, Expressive Law and File-Sharing Norms, 43 SAN DIEGO L. REV. 577, 584–7 (2006). 130 Mazar et al., supra note 5, at 633. 131 2016 Crime in the United States, FBI UNIFORM CRIME REPORT, crime. 132 Philipp Gerlach, Kinneret Teodorescu, & Ralph Hertwig, The Truth About Lies: A at Meta-Analysis Analysis_on_Dishonest_Behavior. Dishonest Behavior, available on 1/1/2019 Feldman & Kaplan people choose to lie and cheat in about 50 percent of all experimental observations.133 What makes this finding even more troubling is that the incentive to cheat in a lab setting is typically relatively small and ethical standards are made explicitly clear to participants. In real life, when possible monetary gains from dishonest behavior are significantly higher and ethical standards are often ambiguous or vague, and ex-post enforcement for such misconducts is limited, cheating is likely to occur even more frequently. In terms of its broader implications, the prevalence of bounded ethicality has a devastating effect on interpersonal trust, which is the foundation of a functioning society.134 Due to ethical biases and individual’s limited ability to make a fully candid moral deliberation, unethical acts become extremely common, and can thereby even become the norm. Therefore, the existence of bounded ethicality can completely undermine any mechanism that relies on people's mutual beliefs in the good intentions and honesty of others.135 If we “know” that “everybody lies” in the marketing world or that everybody steals from work, it makes it very difficult to trust in the integrity of others. Similarly, if students know sexual harassment is the norm in universities, their faith in the educational system and its authorities can be completely shattered. II. BOUNDED ETHICALITY AND LAW ENFORCEMENT The findings of behavioral ethics research, with its emphasis on the ubiquity of bounded ethicality, have deep and troubling implications from a law-enforcement perspective. Mainly, how can the law curb wrongdoing if perpetrators consistently convince themselves they are doing nothing wrong? More generally, if people can subconsciously ignore, excuse and justify their own wrongdoing, what implications does this have for the optimal design of legal policies and institutions? Such queries make the issue of legal compliance markedly more nuanced and more serious than previously appreciated. It seems law enforcement fail to grapple with unethical conduct that arises from the limited awareness of perpetrators. that current assumptions of 133 Id. 134 Robert D. Putnam, Bowling Alone: America’s Declining Social Capital, 6(1) J. DEMOCRACY 65, 65–6 (exploring the concept of social capital and the possible reasons for its decline). 135 For a discussion of this problem in light of the 2008 financial crisis, see Nicole Gillespie & Robert Hurley, Trust and the Global Financial Crisis, in HANDBOOK OF ADVANCES IN TRUST RESEARCH 177 (Reinhard Bachmann & Akbar Zaheer eds., 2013). Big Data & Bounded Ethicality 1/1/2019 A. Ethical Nudges and the New Regulatory Approach Behavioral ethics research recognizes people’s ability to ignore their own wrongdoing. If wrongdoers often fail to understand they are committing a wrong, what can the law do to prevent them from acting badly? Traditional regulatory mechanisms based on deterrence, punishment, rewards, and expressive morality seem ineffective in light of perpetrators' ability to justify their own unethicality and their limited awareness of the full meaning of their wrongdoing.136 1. Deterrence Current legal scholarship emphasizes deterrence as a primary means of curbing illegality.137 Within this framework, scholars study legal rules as sanctions that impose a price on certain types of undesirable behavior.138 Based on assumptions regarding rational decision-making, sanctions have been designed to incentivize wrongdoers to refrain from harming others.139 Generations of legal scholars and law and economics scholars have studied the effects of law on behavior based on the deterrence approach.140 However, in recent decades, the deterrence or cost-benefit model has been criticized on numerous grounds. Some scholars have demonstrated empirically the limits of deterrence in accounting for both self-reported and 136 Max H. Bazerman & Mahzarin R. Banaji, The Social Psychology of Ordinary Ethical Failures, 17(2) SOC. JUST. RESEARCH 111, 111 (2004) (showing that incentives and deterrence will not affect those who think there is nothing wrong with their behavior). 137 FRANKLIN E. ZIMRING, GORDON J. HAWKINS & JAMES VORENBERG, DETERRENCE: THE LEGAL THREAT IN CRIME CONTROL 189-190 (1973); CHARLES R. TITTLE, SANCTIONS AND SOCIAL DEVIANCE: THE QUESTION OF DETERRENCE (1980). 138 This literature, in its current form, originates with Ronald Coase, The Problem of Social Cost, 3 J.L. & ECON. 1 (1960), still the most cited work in legal scholarship (Fred R. Shapiro & Michelle Pearse, The Most Cited Law Review Articles of All Times, 110 MICH. L. REV. 1483, 1489 (2012)). 139 THOMAS J. MICELI, THE ECONOMIC APPROACH TO LAW 1 (2004) (“The economic approach to law assumes that rational individuals view legal sanctions [monetary damages, prison] as implicit prices for certain kinds of behavior, and that these prices can be set to guide these behaviors in a socially desirable direction.”); WERNER Z. HIRSCH, LAW AND ECONOMICS: AN INTRODUCTORY ANALYSIS 1 (1988) (“Laws are authoritative directives that impose costs and benefits on participants in a transaction and in the process alter incentives”); Steven Shavell, Law Versus Morality as Regulators of Conduct 4 AM. L. & ECON. REV. 227, 227 (2002) (“It is evident that both law and morality serve to channel our behavior. Law accomplishes this primarily through the threat of sanctions if we disobey legal rules.”). 140 WILLIAM M LANDES & RICHARD POSNER, THE ECONOMIC STRUCTURE OF TORT LAW 4 (1987) (reviewing the long history of deterrence as a primary goal of the legal system). 1/1/2019 Feldman & Kaplan actual compliance.141 Others have suggested that deterrence does not work in practice for the simple reason that people are, for the most part, unaware of the written law.142 Behavioral scholars have challenged the dominant perception that people are motivated by a fear of sanctions.143 The relative effectiveness of enforcement mechanisms versus levels of punishment in deterring transgressions remains the subject of fierce debate.144 Most studies suggest that the severity of punishment has only a marginal deterrent effect on individual behavioral choices.145 Behavioral ethics research provides an explanation for the failure of deterrence to curb wrongdoing. Self-perceived good people engage in motivated reasoning and often fail to recognize the unethicality of their own actions. Because they are blind, at least partially, to their own unethicality, they therefore have little reason to give appropriate consideration to the possibility that they will be sanctioned for their behavior.146 Thus, the role of the law as a deterrent mechanism is currently limited at best.147 Clearly, imposing harsh punishment does have value in that it can provide a clear message about the state’s approach and commitment to enforcing morality. As we suggest if implemented properly, can also heighten people’s awareness of certain problematic behaviors.148 However, ex post punishments and sanctions increased punishment, later, 141 See John Braithwaite & Toni Makkai, Testing an Expected Utility Model of Corporate Deterrence 25 L. & SOC. REV. 7, 7 (1991). 142 Paul H. Robinson & John M. Darley, Does Criminal Law Deter? A Behavioural Science Investigation, 24(2) OXFORD J. LEGAL STUD. 173, 175–8 (2004). 143 Gary S. Becker, Crime and Punishment: An Economic Approach, 76(2) JOURNAL OF POLITICAL ECONOMY 169 (1968). 144 Id. 145 Theodore G. Chiricos & Gordon P. Waldo, Punishment and Crime: An Examination of Some Empirical Evidence, 18(2) SOCIAL PROBLEMS 200, 217 (1970); George Antunes & Lee A. Hunt, The Impact of Certainty and Severity of Punishment on Levels of Crime in American States: An Extended Analysis, 4 J. CRIM. L. & CRIMINOLOGY 486, 492 (1973); ANDREW VON HIRSCH, ANTHONY E. BOTTOMS, ELIZABETH BURNEY & PER-OLOF H. WIKSTRÖM, CRIMINAL DETERRENCE AND SENTENCE SEVERITY: AN ANALYSIS OF RECENT RESEARCH 63 (1999); Daniel S. Nagin & Greg Pogarsky, Integrating Celerity, Impulsivity, and Extralegal Sanction Threats into a Model of General Deterrence: Theory and Evidence, 39(4) CRIMINOLOGY 865, 892 (2011). Many works support the advantage of certainty over severity; for a review, see Cheryl Marie Webster & Anthony N. Doob, Searching for Sasquatch: Deterrence of Crime Through Sentence Severity, in THE OXFORD HANDBOOK OF SENTENCING AND CORRECTIONS 173, 173 (2012). 146 Adam Fine & Benjamin van Rooij, For Whom Does Deterrence Affect Behavior? Identifying Key Individual Differences, 41(4) L. & HUMAN BEHAVIOR 354, 360 (2017) (demonstrating that people who have high moral disengagement, low self-control and low rule orientation will be less likely to respond to deterrence). 147 Bazerman & Banaji, supra note 136, at 111. 148 FELDMAN, supra note 2, at 69 (Exploring ways by which traditional law enforcement mechanisms can improve deliberation by perpetrators; for instance, people Big Data & Bounded Ethicality 1/1/2019 cannot ensure compliance on their own, as they include no mechanism for ensuring engagement with the awareness of perpetrators.149 The study of the appropriate sanctions, with no attention to the effect of the sanctions on the perpetrator’s awareness, is of little relevance to real-world law enforcement. Behavioral ethicsoffers an alternative to the economic rational choice model of crime, which holds that a potential wrongdoer will choose to behave unethically if the gain from doing so outweighs the expected sanction.150 Conversely, under the behavioral ethics framework, an individual will behave unethically if it is possible to do so while continuing to believe that he or she is a moral person.151 Legal sanctions and deterrence policy must meet this challenge, and be designed bearing bounded ethicality in mind. From a practical perspective, this shift entails an immense challenge, as the purpose of laws and regulations applying this approach is to find potential perpetrators, rather than actual ones, and effectively engage with their state of awareness. 2. Legitimacy Along with deterrence, legitimacy is offered as a principal rationale for compliance with the law. The rich scholarship on compliance and legitimacy posits that people obey the law because they perceive it as legitimate.152 The main indicator for legitimacy is usually described as procedural fairness; that is, individuals tend to obey the law if they think it is the product of a just process of legal deliberation and rule-making.153 Thus, when laws appear fair and legitimate, there is evidence that they shift behavior towards greater compliance and acceptance of organizational rules seem to be more sensitive to the probability of detection than to the severity of punishment; similarly, the expressive effects of punishment seems to be more important than the punishment itself). 149 This is not to say that deterrence doesn’t work in curbing unethically. Some studies do support the rational choice model for ethical decision-making (Isabel Thielmann & Benjamin E. Hilbig, Daring dishonesty: On the role of sanctions for (un)ethical behavior, 79 J. EXPERIMENTAL SOC. PSYCHOL. 71 (2018)). Nonetheless, it is important to take into account the fact that in such studies, it is made explicitly clear to participants that one choice is ethically problematic. This is not always the case in real life contexts, where bounded ethicality can prevent perpetrators from understanding they are behaving unethically. 150 Feldman & Teichman, supra note 28, at 980 (comparing the decision to commit a wrong to the decision to role a die). 151 Mazar et al., supra note 5, at 633. 152 Daniel Kahneman, Jack L. Knetsch, Richard H. Thaler, Fairness and the Assumptions of Economics, 59(4) J. BUS. S285, S299 (1986). 153 TOM R. TYLER, WHY PEOPLE OBEY THE LAW (1990). 1/1/2019 Feldman & Kaplan in various environmental compliance155 and greater organizational ethicality.156 legal contexts,154 as well as towards more sensitive The concept of legitimacy as a basis for compliance suffers from similar limitations to those discussed above in the context of deterrence. In short, there are no practical regulatory tools for ensuring that people are aware of the law and its fairness when they decide whether or not to behave unethically. While deterrence and legitimacy are perceived as fostering compliance in different ways, the effectiveness of both is still predicated on the assumption that people make deliberate decisions regarding the law. Thus, much of the current literature on legal compliance examines people’s decision-making in the context of ethical dilemmas, ignoring the possibility that people might engage in motivated reasoning and self-deception. The rich experimental literature on compliance assumes that people recognize a moral conflict and then proceed to shape their actions accordingly. This approach fails to address the fact that people may ignore the conflict to begin with, or simply reason it away. The assumption underlying compliance theory is that people evaluate the fairness, procedural or other, of the law and then make a conscious decision as to whether or not to comply. For example, Fishbacher et al. have measured levels of compliance by asking people to make a choice to either comply or behave unethically, clearly defining the choice between doing “good” or “bad.”157 This framing explicitly ignores the possibility that people's bounded ethicality will undermine their ability to recognize their choice as being the “bad” one. Behavioral ethics research shows that, in reality, motivated reasoning often leads individuals to think that the choice that serves them best is also ethically permissible.158 Again, these insights call for a change in emphasis in law enforcement. Instead of trying to make sure that laws appear procedurally legitimate, policy makers should focus their efforts on improving the ability of potential perpetrators to appreciate that they are indeed in violation of these 154 Yuval Feldman & Tom R. Tyler, Mandated Justice: The Potential Promise and Possible Pitfalls of Mandating Procedural Justice in the Workplace, 6(1) REG. & GOVERNANCE J. 46, 46 (2012). 155 Yuval Feldman & Oren Perez, Motivating Environmental Action in a Pluralistic Regulatory Environment: An Experimental Study of Framing, Crowding Out, and Institutional Effects in the Context of Recycling Policies 46(2) L. & SOC. REV. 405 (2012). 156 Yuval Feldman & Orly Lobel, The Incentives Matrix: The Comparative Effectiveness of Rewards, Liabilities, Duties, and Protections for Reporting Illegality, 88 TEX. L. REV. 1151, 1151–2 (2009). 157 Urs Fischbacher, Simon Gächter & Ernst Fehr, Are People Conditionally Cooperative? Evidence from a Public Goods Experiment, 71(3) ECON. LETTERS 397, 398– 9 (2001). 158 Kunda, supra note 81, at 480. Big Data & Bounded Ethicality 1/1/2019 laws. Of course, once this understanding is achieved, perceptions of legitimacy might prove to be important in ensuring compliance. Yet, for people who are not engaging in ethical deliberations and are not made more fully aware of the unethicality of their actions, legitimacy on its own cannot achieve compliance. 3. Ethical Nudges The analysis of deterrence and legitimacy offered above highlights the flawed assumptions that underlie our legal system and the resulting failure of existing regulatory approaches to provide an adequate response to most instances of wrongdoing. Incentives-based enforcement fails to correct a large proportion of unethical actions, because “such measures simply bypass the vast majority of unethical behaviors that occur without the conscious awareness of the actors, who engage in them.”159 Indeed, many psychologists who focus on ethical decision-making challenge the assumptions held by most legal scholars about self-control, autonomy, and responsibility for action, which are fundamental to contemporary regulatory theory and to the operation of most enforcement measures. The key challenge addressed by this Article is how to create a regulatory policy to deal with misconduct perpetrated with varying levels of awareness and motivation. To ensure compliance with the law, it is not enough to threaten individuals with sanctions, nor it is sufficient to ensure that laws are perceived as fair. The key to regulating misconduct is to find ways of enabling perpetrators to evaluate their actions more candidly,160 taking into consideration the possible legal ramifications of those actions and the procedural fairness of legal rules. In this sense, the concepts of deterrence and legitimacy must be reexamined and redefined, as they are being incorporated into a new behavioral framework that focuses on decision-making. In regulating conduct, therefore, it is not sufficient to increase the effectiveness of underlying incentive structures, since perpetrators are not necessarily aware of them. Rather, it is more important to improve deliberation and ethical engagement by enhancing people’s ability to evaluate the relevance of the existing legal incentive structure for their own particular actions.161 We refer to such regulatory tools as ethical nudges, acts of intervention designed to nudge potential perpetrators towards more virtuous conduct. Such nudges have been shown to be highly effective. For example, in some settings it has been shown that making people sign an 159 Bazerman & Banaji, supra note 136, at 111. 160 FELDMAN, supra note 2, at 88. 161 Id. 1/1/2019 Feldman & Kaplan ethical code of conduct prior to taking action can eliminate wrongdoing almost completely.162 tools, regulatory This goal can be achieved in several ways, and ethical nudges can take many different forms. First, to improve behavior, regulators can directly target the awareness of perpetrators, thereby eliciting more candid ethical deliberation. This can be achieved using ethical alerts, and a variety of other de-biasing mechanisms. Such if designed appropriately, can address the problem of bounded ethicality by encouraging perpetrators to use System 2 thinking and override self-serving biases.163 These techniques can prompt potential wrongdoers to consider the effects of their actions, to view the situations from the perspective of potential victims, or to report their decisions to an objective third party. The choice of regulatory tool depends on the particular bias hindering ethical deliberation. Consequently, if a perpetrator engages in motivated reasoning and interprets a situation in a way that makes it difficult to see the wrongfulness of the contemplated actions, it may be necessary to alert that individual to the true nature of the situation. Alternatively, if a perpetrator is morally disengaged, in that he or she is aware of the facts of the situation, but finds ways to justify the misconduct, an ethical nudge emphasizing the victims of such misconduct or reminding the potential perpetrator of possible legal sanctions may be effective in preventing misconduct. Another form of ethical nudge is the use of situational design, aimed at improving ethical deliberation indirectly, by eliminating ethical blind spots and situations that lead to unethicality. Bounded ethicality is strongest in situations in which people find it easy to ignore their own wrongdoing.164 Regulators’ ability to prevent such situations can prove crucial in reducing misconduct. That is, instead of engaging with perpetrators’ awareness directly through the use of ethical alerts, regulators may instead redesign problematic situations to ensure that ethical blind spots are not created in the first place. To illustrate this alternative approach, consider again the widespread problem of sexual harassment in the workplace. Research on sexual harassment indicates specific circumstances under which sexual harassment is more common,165 such as in male-dominated environments or under male 162 Shu, Gino & Bazerman, supra note 53, at 344. 163 Christine Jolls and Cass R. Sunstein, Debiasing through Law, (March 2005). U Chicago Law & Economics, Olin Working Paper No. 225; Harvard Law and Economics at No. Discussion SSRN: or Available Paper 495. 164 FELDMAN, supra note 2, at 2, 16, 48. 165 Tenbrunsel et al., supra note 9, at 247 (the authors investigate “the contextual influences surrounding sexual harassment”.); Deborah Erdos Knapp, Robert H. Faley, Steven E. Ekeberg & Cathy L. Z. Dubois, Determinants of Target Responses to Sexual Big Data & Bounded Ethicality 1/1/2019 supervisors.166 Apparently, in such settings, individuals have found it easier to shrug off aggressive sexual behavior as harmless or accepted. One obvious way to address this problem would be to provide sexual harassment training, which would directly increase the level of awareness of potential perpetrators. Another course of action would be to reshape the situation, thereby eliminating the circumstances in which perpetrators find it easier to ignore or excuse their own unethicality. This can be achieved, for example, by ensuring equal representation for women in the workplace or in executive positions.167 Note that ethical nudges are related to, yet distinct from, traditional nudges, as popularized by Sunstein and Thaler. Traditional nudges are policy interventions designed to change behavior without creating economic incentives or limiting people's freedom of action by eliminating other possibilities. They aim at improving people’s ability to make informed and rational choices that will maximize their own well-being.168 In contrast, ethical nudges are designed to encourage more ethical conduct and to reduce the harm imposed on others. The following sections offer four general types of ethical nudges, and detail the various applications of each one. B. The Challenges for Ethical Nudges The discussion above outlines a regulatory framework designed according to the central insights of behavioral ethics research. In practice, the applications of this regulatory approach would involve several significant challenges that are discussed in detail below. Harassment: A Conceptual Framework, 22 ACADEMY MANAGEMENT REV. 687, 709 (1997) (“sexual harassment does not occur in a vacuum but, rather, in an organizational environment that affects the way people behave”); Chelsea R. Willness, Piers Steel, Kibeom Lee, A Meta-Analysis of the Antecedents and Consequences of Workplace Sexual Harassment, 60 PERSONNEL PSYCHOL. 127 (2007) (the authors study the role played by leaders and organizations in the slippery slope, giving or denying a harasser the opportunity to harass again in the future). 166 Myrtle P. Bell, Mary E. McLaughlin & Jennifer M. Sequeira, Discrimination, Harassment, and the Glass Ceiling: Women Executives as Change Agents 37(1) J. BUS. ETHICS 65, 66–7 (2002) (highlighting the connection between sexual harassment and sex- segregation in the workplace). 167 Id. at 68–9 (arguing that appointing more women executives can reduce sexual harassment); James E. Gruber, The impact of male work environments and organizational policies on women’s experiences of sexual harassment, 12 GENDER & SOC. 301, 320 (1998). 168 THALER & SUNSTEIN, supra note 79. 1/1/2019 Feldman & Kaplan 1. Real Time Responses Behavioral ethics research shows that misconduct originates with the bounded ethicality of individuals,169 that is, with their biased thinking and limited ability to conduct a full and candid moral deliberation at the time they take action.170 This means that the first challenge for law enforcement is to induce awareness in real time. In order to influence behavior and actually reduce misconduct, regulators and law enforcers must find ways to effectively engage with people’s ethical deliberation and with their real-time decision- making process.171 This need to implant the law into people’s consciousness more effectively is a considerable practical challenge. It also represents a significant addition to the current understanding of law enforcement and compliance, which does not explicitly consider bounded ethicality and the need to engage with the moral awareness of potential perpetrators. For example, when considering deterrence, law enforcement efforts should focus not on punishing the guilty ex post facto but on ensuring that the possibility of punishment effectively triggers candid moral deliberation in real time, when potential perpetrators are considering, or failing to consider, the potential harmfulness of their own actions. 2. Ethical Numbing Behavioral ethics research suggests that bounded ethicality is in many ways an unavoidable component of the human psyche.172 People are ethically bound due to a long list of cognitive limitations and those cognitive limitations, together with the consequences of bounded ethicality, are here to stay. Just as it is unlikely that we will be able to remedy bounded rationality and make people generally more rational, it is similarly unlikely that we will find general solutions to the problems of bounded ethicality and will be able to make people generally more ethical. There are many ways in which the motivating force behind people’s ethical biases has many positive attributes, as its aim is to enhance people’s self-perceptions.173 What behavioral ethics suggests that what is possible is to help individuals make better and more acceptable moral judgements in specific instances by triggering more candid moral deliberation in opportune times.174 This 169 FELDMAN, supra note 2, at 1. 170 Id. at 152. 171 Id. at 88. 172 Chugh & Kern, supra note 52, at 85. 173 Greenwald & Banaji, supra note 4, at 10–11. 174 Shu, Gino & Bazerman, supra note 53, at 344. Big Data & Bounded Ethicality 1/1/2019 necessitates a targeted regulatory approach, whereby policy makers know when to activate regulatory interventions. To improve ethical deliberation, regulatory intervention must be thoughtful and targeted, so as to avoid the dangers of ethical numbing.175 To improve deliberation by wrongdoers, policy makers must be able to deploy nudges in appropriate moments. If ethical nudges are untargeted and used constantly, they will lose all effectiveness. Ethical alerts are more effective if they disturb rather than become part of routines. Only if ethical nudges disturb the routine can they prompt individuals to make more candid ethical deliberations. In essence, to avoid moral numbing, ethical alerts must stand out. For all these reasons, the practical challenge for any regulatory scheme that attempts to improve ethical deliberation is to be narrow and targeted, rather than general and broad. 3. Selecting Among Nudge Types To effectively regulate unethical conduct, policy makers must be able to match appropriate regulatory responses to different cases. Behavioral ethics research shows that unethical behavior originates with many distinct types of ethical biases. Ethical nudges, those regulatory interventions designed to improve deliberation, will only be effective if they are responsive to the specific causes of bounded ethicality in each specific case. To select the most effective intervention, regulators will need to know which cognitive mechanisms are responsible for generating misconduct in specific cases. For instance, assume a wrongdoer behaves unethically because he or she is able to convince himself or herself that the particular behavior harms no one. If this is the case, the most direct way to improve deliberation would be to alert the perpetrator to more candidly consider the possible harm caused to others. Alternatively, assume a wrongdoer commits an offense because the legal standard is ambiguous, making it easier for perpetrators to convince themselves that their behavior is permitted. In such a case, the simplest, most effective intervention is to clarify the legal rule or to nudge the perpetrator to make a more candid deliberation of its meaning. The following paragraphs offer a menu of such ethical nudges, and highlight the importance of the ability to make an informed choice among them. Behavioral ethics research shows that motivated reasoning causes perpetrators to ignore or disregard crucial facts, thus enabling them to avoid ethical conflicts instead of facing them.176 To overcome this mechanism, regulators could use ethical alerts to remind potential perpetrators of facts 175 Tenbrunsel & Messick, supra note 54, at 228. 176 Kunda, supra note 81, at 480. 1/1/2019 Feldman & Kaplan they might otherwise ignore, or to prompt perpetrators to engage in more fitting ethical deliberations. Ethical alerts are simple cues that can be used to trigger moral deliberation. Placing such ethical reminders at crucial junctures of possible misconduct can significantly lower the risk of wrongdoing. Thus, upon placing a request for office supplies on a company's computerized system, an employee may be reminded that companies regularly go bankrupt due to employee theft. Such measures can be highly effective. For example, in a recent meta-analysis, Kobis and colleagues show that intuitive dishonesty disappears if perpetrators are reminded of potential injuries to victims.177 That is, when making ethical choices, intuitive thinking leads people to reach self-serving decisions, but only when no specific individual is assumed to get hurt.178 Prompting perpetrators to consider the case of a specific potential victim can improve conduct even if decision-making remains intuitive rather than deliberate.179 Similarly, employees may be reminded that stealing is wrong, that office supplies cost money, that consumer goods cost 10 to 15 percent more due to employee theft, that employee theft is a major societal issue, costing ten times more than domestic break-ins, and that it is a crime and punishable by severe fines. Behavioral ethics research has shown that such reminders can significantly improve behavior in varied contexts.180 Alerting potential perpetrators to such facts can trigger ethical deliberation and make it more difficult for them to dismiss employee theft as ethically weightless. Thus, in some cases, just reminding perpetrators of possible legal sanctions may be the most effective route, while in other cases it may be more productive to remind them of the injuries their actions can cause others. Note that such reminders may also refer to the potential penalty for violation of duty or a breach of the obligation to signal the true value of a good. Adding references to legal sanctions may help people recognize that their true self-interest lies in overcoming their tendency to deceive themselves.181 Yet in other cases, it may make the most sense not to remind individuals 177 Nils C. Köbis, Bruno Verschuere, Yoella Bereby-Meyer, David Rand & Shaul Shalvi, Intuitive (Dis)honesty – A Meta-Analysis, 17 (working paper 2018). 178 Id. 179 Bandura, supra note 54, at 203 (showing that people find it very difficult to cause harm to an identified victim, due to the “power of humanization”). 180 For example, it has been shown that unethicality is more common when individuals are mindless of their own ethical standards; if they are reminded of these standards, unethicality subsides (Mazar et al., supra note 5, at 635). 181 Yuval Feldman and Eliran Halali, Regulating 'Good' People in Subtle Conflicts of Interest Situations, J. BUS. ETHICS 1 (2017) (showing that reminders with ethical content and reminders regarding possible sanctions can yield similar effects in improving behavior). Big Data & Bounded Ethicality 1/1/2019 of any specific outcome or fact, but simply to prompt them to engage independently in System 2 ethical moral deliberation.182 This can be achieved, for instance, by directing people’s attention to ethical symbols or messages. Studies have shown that individuals are less likely to act badly after reading morally laden texts, even short ones. Such measures are designed to prompt potential wrongdoers to consider the effects of their actions, to view situations from the perspective of potential victims, or to report their decisions to an objective third party. De-biasing tools employ a variety of cognitive-based techniques to overcome biased thinking and non- deliberative choices and make it possible for people to engage more fully in moral deliberation.183 These goals can be achieved through mechanisms that encourage reflection and self-awareness. Reflection can be achieved directly, by forcing individuals to take a few extra moments to consider the implications of their actions. This can be especially useful in curbing routine unethicality and discouraging work-related misconduct. For example, upon making sales of certain types, financial advisors may be prompted to take a moment to consider the deal they are offering. JPMorgan Chase routinely sends electronic warnings to its traders reminding them to make sure they are remaining within the boundaries of the personal trading rules.184 These measures alert employees to engage in System 2 thinking before completing the task at hand.185 Similarly, tailored generated alerts might occasionally require the sales representatives to record face-to-face meetings or phone calls. Alternatively, sales representatives could be required to produce written protocols, report their actions to a colleague or a supervisor, or to share more information with their clients. Such prompts can serve as a disruption of the professionals’ routines, encouraging them to use their System 2 thinking and gain a different perspective on their situations. to curb misconduct by sales representatives, Accountability mechanisms are also a highly useful form of de-biasing, whereby individuals are asked to explain the reasoning for their decisions 182 Shahar Ayal, Francesca Gino, Rachel Barkan & Dan Ariely, Three Principles to REVISE People’s Unethical Behavior, 10(6) PERSP. ON PSYCHOL. SCI. 738, 739–40 (2015). Here, the authors offer their REVISE system, which stands for REmind, VIsibility, and SElf-engagement. Under this three-step approach, first, individuals are reminded of the need to engage in moral deliberation. Second, people are made aware of their own visibility: the fact that their actions are being observed by people who know them. Finally, this approach calls for moral self-engagement, aiming to minimize the gap between people’s self-perception of morality and their actual conduct. 183 Jolls & Sunstein, supra note 163; FELDMAN, supra note 2, at 58. 184 Haugh, supra note 47, at 712, 736. 185 Id. 1/1/2019 Feldman & Kaplan after the fact.186 This tool is useful in a variety of situations, because the mere act of justifying one’s actions, particularly in writing, prompts reconsideration. First, merely articulating a justification can prompt System 2 thinking, which, by itself, can sometimes overcome ethical biases. Second, people's awareness of the possibility that their written reports may be read by somebody else can also trigger caution and deliberation. Importantly, the benefit of accountability reports is manifest even in those cases when they are not actually read. The very requirement of writing them suffices to reduce wrongdoing, as it makes it significantly more difficult for perpetrators to ignore or excuse their own actions. Accountability mechanisms may prove especially useful when wrongdoers operate under a veil of anonymity, are confident that their wrongdoing will not be discovered, or do not know the potential victims of their actions. Behavioral ethics research indicates that misconduct is especially common when there is no single identified victim, but rather many unidentified ones.187 This is because moral deliberation is often triggered by personal interaction. Accountability mechanisms can substitute for such interaction when it is otherwise missing. Declarations of various types also offer opportunities to mitigate the effects of bounded ethicality.188 Declarations include any measure prompting individuals to state their commitment to a code of conduct, to ethical behavior generally, or to adherence to a legal standard. Such speech acts have been shown to trigger moral deliberation in many situations. A simple example of the use of declarations is found in the context of corporate governance or fiduciary duties. For example, before important votes are made, directors and executives could be required to sign declarations stating they are aware of the legal standards under which they operate, that they know what types of conflicts of interest they are obligated to disclose and that such conflicts are not present.189 Such declarations serve a dual purpose. First, according to behavioral ethics research, actively declaring adherence to the legal standard in writing can reduce unethical behavior. Requiring people to actively declare their intentions prevents them from downplaying the omissions of important facts190 or excusing 186 Jennifer S. Lerner & Philip E. Tetlock, Accounting for the Effects of Accountability, 125(2) PSYCHOL. BULLETIN 255, 255–6 (1999). 187Amitai Amir, Tehila Kogut & Yoella Bereby-Meyer, Careful Cheating: People Cheat Groups Rather Than Individuals, 7 FRONTIERS IN PSYCHOL. 371, 371 (2016). 188 On the use of declarations, see FELDMAN, supra note 2, at 199. 189 Id. at 200. 190 Andrea Pittarello, Enrico Rubaltelli & Daphna Motro, Legitimate Lies: The Relationship Between Omission, Commission, and Cheating, 46 (4) EUR. J. SOC. PSYCHOL. 481, 491 (2016). Big Data & Bounded Ethicality 1/1/2019 themselves for telling passive lies.191. Requiring a declaration changes the status of the unethical conduct, making it much less likely that executives will fail to announce a conflict of interest. Second, from a legal perspective, signing a declaration reminds people that they can be prosecuted for perjury. Reminders of legal consequences have been shown to be effective in preventing even subtle conflict of interests.192 The different types of ethical nudges can all improve ethical deliberation in relevant cases. Behavioral ethics research offers a large assortment of regulatory tools that might be helpful in reducing misconduct in different situations. The crucial point is that, to effectively combat unethicality, regulators must be able to make informed choices and match the appropriate regulatory responses to different situations and types of misconduct. 4. The Scope of Regulation Behavioral ethics research shows that unethical behavior is not confined to any specific segment of the population comprised of particularly malevolent individuals.193 Rather, unethical behavior is nearly universal and is commonly practiced by the majority of ordinary people.194 Thus, lab experiments show that bounded ethicality makes unethical conduct nearly universal under certain circumstances. 195 In a recent meta-analysis of studies involving more than 30,000 participants, researchers found that people choose to lie and cheat in about 50 percent of all experimental observations.196 These facts present an immense challenge from a law enforcement perspective. To curb unethicality, it is not enough to identify and punish extreme divergences from prevalent moral and legal norms. Instead, regulators should adopt a broader perspective and more seriously consider the structural sources of systematic and persistence wrongdoing by “ordinary” people. 5. Willingness to be Nudged Another challenge in regulating bounded ethicality relates to people’s incentives and willingness to be nudged. Ethical nudges are different from 191 Mark Spranca, Elisa Minsk & Jonathan Baron, Omission and Commission in Judgment and Choice, 27(1) J. EXPERIMENTAL SOC. PSYCHOL. 76, 76–7 (1991). 192 Feldman & Halali, supra note 181, at 65 (showing that reading a text about possible punishment for corruption caused experiment participants to behave more ethically). 193 ARIELY & JONES, supra note 8. 194 Id. 195 Gerlach et al, supra note 132. 196 Id. 1/1/2019 Feldman & Kaplan regular nudges and require additional persuasive force. Traditional nudges, following the model proposed by Tahler and Sunstein, aim to help people overcome the cognitive biases which prevent them from promoting their own self-interest.197 In contrast, ethical nudges aim to help people engage in more candid moral deliberation, and consider the interests of others.198 Therefore, if ethical nudges are to succeed in combating bounded ethicality and improving ethical decision-making, they must be more forceful and more difficult to ignore or downplay than traditional nudges. Ethical nudges work in opposition to people’s natural incentive system, and not in support of it, and therefore require additional support in order to be effective. Therefore, a “naked” ethical nudge will not always be potent enough to cause people to be aware of the ethical implications of their behavior, and such nudges may need to be reinforced or accompanied by an external legal threat. For that reason, legal sanctions designed in accordance with nudge approach insights could prove most effective. Such instruments, while reminding people of their unethical tendencies, will also draw their attention to the potential legal consequences of their unethical behavior. When functioning as nudges, the legal instruments should be designed to focus less on changing people’s cost-benefit calculation and more on increasing their awareness of the full implications, including legal ones, of their wrongdoing. Therefore, in addition to the soft regulatory measures mentioned above, bounded ethicality can be regulated through more traditional means, if those are adjusted appropriately. That is, in some cases, the most effective way to improve ethical deliberation is by increasing sanctions and enforcement efforts, if this is done in a way that will effectively change the ethical deliberation of potential perpetrators. Making perpetrators consider the fact that punishment is more likely, or more severe, can sometimes be the best way to improve their moral awareness. In making this observation, our approach helps remedy an additional limitation of the current literature, wherein nudges are seen as moving on a separate track in comparison to the classical command and control approach to regulation.199 Nudges are usually developed as extra-legal instruments and are seen as competing with more traditional command and control legal interventions.200 Our argument is that in ethically problematic situations, 197 THALER & SUNSTEIN, supra note 79. 198 FELDMAN, supra note 2, at 198–9. 199 Orly Lobel, The Renew Deal: The Fall of Regulation and the Rise of Governance in Contemporary Legal Thought, 89 Minn. L. Rev. 262, 265-6 (2004) (contrasting the command-and-control perception of regulation with a novel, softer, approach). 200 Richard H. Thaler & Shlomo Benartzi, Save More Tomorrow™: Using Behavioral Economics to Increase Employee Saving. J. POL. ECONOMY, 112(S1), S164–S187 (2004) (suggesting nudges and choice architecture as alternative route for improving consumers’ Big Data & Bounded Ethicality 1/1/2019 ones which could be termed societal blind spots, traditional legal instruments should be seen as a type of nudge, operating to improve deliberation and overcome biased thinking. Importantly, this may result in a regulatory focus quite different from what we currently observe. Behavioral ethics research shows that unethicality is most prevalent in situations where legal standards are vague,201 or misconduct is manifested in subtle, rather than obvious, violations and without identifiable victims.202 Therefore, enforcement should be targeted at situations which constitute societal blind spots, where many more people are likely to engage in wrongdoing, as opposed to clear- cut examples of misconduct in which far fewer people are likely to engage. III. THE PROMISE OF BIG DATA REGULATION Recent years have witnessed an unprecedented increase in the use of big data as a means to improve prediction and decision-making.203 Big data analytics are already being employed by a wide range of organizations, from finance and healthcare to law enforcement.204 As eloquently put by Julie Cohen, big data is both a technology and a process. The technology involves information processing hardware able to analyze vast quantities of data in very short times. The process entails the use of the technology to identify patterns in the data, establish data-driven predictions, and apply them further.205 The product of this procedure is an extreme form of amalgamated knowledge.206 Big data analytics necessitates large amounts of information, often measured in petabytes and consisting of tens of millions of distinct observations.207 Big data typically involves rapid data processing financial decisions, instead of more traditional regulatory means). 201 Constantine Boussalis, Yuval Feldman & Henry E. Smith, Experimental Analysis of the Effect of Standards on Compliance and Performance, 12(2) REGULATION & GOVERNANCE 277, 277-8 (2018) (providing empirical evidence for empirical the effect of legal ambiguity on behavior). 202 Amitai Amir, Tehila Kogut & Yoella Bereby-Meyer, Careful Cheating: People Cheat Groups Rather Than Individuals, 7 FRONTIERS IN PSYCHOL. 371, 371 (2016). 203 Angèle Christin, From Daguerreotypes to Algorithms: Machines, Expertise, and Three Forms of Objectivity, 46(1) ACM COMPUTERS & SOC’Y 27, 28 (2016). 204 Id. at 28. 205 Julie E. Cohen, What Privacy Is For, 126 HARV. L. REV. 1904, 1920–21 (2013) 206 For other definitions of big data, see David Lazer & Jason Radford, Data ex Machina: Introduction to Big Data, 43 ANN. REV. SOC. 19, 19 (2017) (emphasizing the context dependence of any definition of big data); VIKTOR MAYER-SCHÖNBERGER & KENNETH CUKIER, BIG DATA: A REVOLUTION THAT WILL TRANSFORM HOW WE LIVE, WORK, AND THINK 2–3 (2013). 207 Sarah Brayne, Big Data Surveillance: The Case of Policing, 82(5) L. & SOC’Y REV. 977, 980 (2017). 1/1/2019 Feldman & Kaplan from disparate sources, merging information from previously separate databases. Current applications of big data include spam and fraud detection, credit score assignment, insurance pricing, as well as data-driven policing and law enforcement.208 In the context of law enforcement, big data is used for a wide range of purposes, including individual and geographical predictions of gun violence209 and other serious crimes.210 This Part explores the advantages of big data analytics in terms of its ability to curb the ills of bounded ethicality. We propose a use of big data never before developed in the literature, and still underused by regulators. We propose the use of big data not only in policing efforts designed to prevent severe crimes, but mainly for predicting other types of misconduct which arise not from violent tendencies, but from the bounded ethicality of potential perpetrators. We show that the characteristics and advantages of big data regulation make it particularly suited to achieving this goal. In the following sections, we highlight some of the new capabilities that big data analytics can offer to policy makers, as described in the growing literature on data-driven law enforcement. We then show that these newly found abilities can help address the challenges raised by bounded ethicality, as described in Part II above. A. Predictive Regulation The proliferation of big data analysis represents a paradigm shift in the general approach to the use of information. In the past, information was gathered and analyzed after the fact in response to past events, and not in anticipation of future developments.211 In the context of law enforcement, this shift represents a change in focus from investigation efforts after a crime has been committed to the effort to predict misconduct before the fact.212 Using big data analysis to help predict misconduct before the fact 208 Sarah Brayne, Big Data Surveillance: The Case of Policing, 82(5) L. & SOC’Y REV. 977, 980 (2017). 209 Andrew V. Papachristos, David M. Hureau & Anthony A. Braga, The Corner and the Crew: The Influence of Geography and Social Networks on Gang Violence, 78(3) AM. SOCIOLOGICAL REV. 417, 418, 425 (2013) (Offering a network model that predicts the identity of individuals most likely to participate in gang violence). 210 WALTER L. PERRY, BRIAN MCINNIS, CARTER C. PRICE, SUSAN C. SMITH & JOHN S. HOLLYWOOD, PREDICTIVE POLICING: THE ROLE OF CRIME FORECASTING IN LAW ENFORCEMENT OPERATIONS 13 (2013). 211 Sarah Brayne, Big Data Surveillance: The Case of Policing, 82(5) L. & SOC’Y REV. 977, 978 (2017) (“data are increasingly used for predictive, rather than reactive or explanatory, purposes”). 212 Andrew G. Ferguson, Big Data and Predictive Reasonable Suspicion, 63(2) U. PA. L. REV. 327, 369 (2015) (reviewing the shift from inquiry to predictive policing). Big Data & Bounded Ethicality 1/1/2019 provides the tools needed for dealing with bounded ethicality and engaging with the awareness of potential perpetrators in real time. If regulators are increasingly able to produce reliable predictions regarding possible misconduct, they can trigger deliberation by possible wrongdoers before they act and offer alerts reminding them of the effects of their behaver or of possible sanctions in real time. Users of alert-based systems, whether regulators or potential perpetrators themselves, can receive real-time notifications when variables that are predictive of misconduct appear in the data. This is made possible by the high frequency of observations and the speed of data processing. The move towards data-driven enforcement thereby supplies, for the first time, the basic framework necessary for facing the regulatory challenge posed by bounded ethicality. B. Targeted Regulation Data-driven law enforcement allows regulators and policy makers to focus their efforts and initiate regulatory interventions that target specific risks and behaviors. This represents a shift from a random check mentality to a targeted intervention approach. That is, instead of deploying enforcement efforts randomly, law enforcers can use data analysis to direct their activity towards the focal points of criminal activity.213 In the context of bounded ethicality, this newfound ability is crucial for overcoming the danger of ethical numbing discussed above.214 To improve ethical deliberation, regulatory intervention must be targeted and specific, rather than general and broad. For example, ethical alerts are effective only if they are targeted and rare, rather than routine and constant. If everyone is randomly bombarded with ethical messages, those messages will quickly lose their meaning and impact.215 More generally, targeted intervention is necessary, as it is almost impossible to generate a general, rather than a temporary, improvement in people’s ethical capacities.216 Big data analysis offers a crucial advantage here, as it facilitates a regulatory scheme that only becomes operative when analysis of background information indicates that its involvement is necessary. C. Tailored Regulation 213 Sarah Brayne, Big Data Surveillance: The Case of Policing, 82(5) L. & SOC’Y REV. 977, 978 (2017). 214 Gino et. al., supra note 91 (showcasing the phenomenon of “ethical depletion” through four experimental studies). 215 Greenwald & Banaji, supra note 4, at 10–11. 216 Chugh & Kern, supra note 52, at 85. 1/1/2019 Feldman & Kaplan Big data analysis offers an abundance of information regarding multiple observations.217 This information can guide policy makers when choosing the most appropriate regulatory response for each specific case. In this, the advantages of data-driven law enforcement can provide tools to overcome the challenge of choosing the right tools to effectively trigger deliberation and address bounded ethicality. This will be crucial in determining the most appropriate legal response, according to the nature of the ethical bias preventing candid deliberation. There are two primary ways to use data analysis for uncovering the cognitive sources of unethicality. First, these cognitive mechanisms might be observed directly through big data analysis of existing cases of misconduct. Big data analysis can provide a plethora of information on specific cases of misconduct, in a way that will enable regulators to devise the most appropriate regulatory response. As mentioned above, behavioral ethics research highlights the great diversity of enforcement means, and their suitability for different types of situations and for different types of ethical biases. For example, big data analysis could help clarify whether the likely offender in a given situation is driven by lack of ethical motivation or by lack of ethical awareness. Situations in which many of the likely transgressors are first-time offenders are more likely to be characterized by ethical blind spots relative to situations in which the transgressor is a repeat protagonist, making the possibility of unfamiliarity with the ethical problem of the behavior less likely. Moreover, using big data, we can also learn the transgression history of the most common transgressors and recognize the most suitable ethical nudges. Essentially, the history of the violations of the typical transgressor could be used to generate better predictions not just of the situational characteristics where we expect increased levels of unethical behavior, but also of the characteristics of the interventions which will be effective, based on their past efficacy across different situations. Second, policy makers may be able to determine indirectly which mechanism is operative by using big data analysis together with an approach of experimental regulation.218 In this experimental approach, different interventions, designed to overcome different types of biases and chosen from a large menu of mechanisms used to improve deliberation, will be deployed randomly. In the second stage, big the first stage of 217 Sarah Brayne, Big Data Surveillance: The Case of Policing, 82(5) L. & SOC’Y REV. 977, 980 (2017). 218 The more common term is experimental legislation (see Sofia Ranchordas, The Whys and Woes of Experimental Legislation, 1(3) THEORY & PRAC. LEGIS. 415 (2013)), but the term experimental regulation is also mentioned frequently and fits under the same analytical framework (Id. at 415). In both cases, the term refers to the idea that policy makers should aspire to evaluate the effects of legislation or regulation either prior to or after their implementation (Id. at 417). Big Data & Bounded Ethicality 1/1/2019 data analysis will be used, for a second time, to evaluate the effectiveness of the different measures that were used and find those that proved most effective. This information, together with behavioral ethics research findings, can help policymakers infer the cognitive sources of unethicality and fine tune the type of regulatory intervention going forward. Randomized content can use the protocols of experimental design and their varying effects using big data analysis. After randomized messages are deployed, big data analysis can provide insights into the effectiveness of each one. Thus, in some cases, reminding perpetrators of possible legal sanctions may be the most effective route, while in other cases, it may be more productive to remind them of the harms their actions can cause others. Note that such reminders may also refer to the potential penalty for violation of a duty or a breach of the obligation to signal the true value of a good. Adding references to legal sanctions may help people recognize that their true self-interest lies in overcoming their tendency to deceive themselves.219 D. Integrated Datasets An important feature of big data is the integration of data from previously separate institutional sources.220 Law enforcement has always been data-driven to an extent. That is, police have traditionally used limited data sets, documenting finger prints, past convictions, or other relevant information.221 The move towards big data entails the merging of information from multiple sources and its systematic and integrated analysis.222 Such an integrated system allows users to track disparate data points in relation to one another and study correlations between data points originating in different datasets. The move towards integrated data is especially relevant in light of behavioral ethics findings. Behavioral ethics research emphasizes that misconduct and unethicality do not originate solely with abnormally malevolent individuals, but also with ordinary, respectable people. This 219 Feldman & Halali, supra note 181, at 65 (showing that reminders with ethical content and reminders regarding possible sanctions can yield similar effects in improving behavior). 220 Andrew G. Ferguson, Big Data and Predictive Reasonable Suspicion, 63(2) U. PA. L. REV. 327, 353 (2015) (tying the rise of big data analytics with the newfound ability “to connect previously discrete data networks”). 221 Richard Berk, Balancing the Costs of Forecasting Errors in Parole Decisions, 74 ALB. L. REV. 1071, 1074 (2010/2011) (discussing the use of historical data to identify future offenders). 222 Sarah Brayne, Big Data Surveillance: The Case of Policing, 82(5) L. & SOC’Y REV. 977, 993 (2017). 1/1/2019 Feldman & Kaplan means that an effective regulatory scheme requires information beyond the narrow focus of the documentation of the actions of repeat criminal offenders. Rather, to prevent unethical conduct, law enforcers and regulators will need access to information regarding the antecedents of misconduct by all people. This accords with the move towards integrated data.223 Traditionally, law enforcers used datasets that include information on individuals who have previously been arrested or convicted of crimes. The recent move towards big data law enforcement entails a departure from this tradition, in favor of the inclusion of information on those with no prior contact with law enforcement authorities.224 Policy makers can now regulate also people with no prior encounters with the law, which is crucial in light of the understanding that bounded ethicality is universal. Such an integrated approach can be illustrated through recent work by Cantalupo & Kidder, who utilized the latest advances in data availability to analyze and categorize sexual harassment by university faculty members.225 They use a database drawn from media reports,226 federal civil rights investigations by the United States Departments of Education and Justice, 227 lawsuits by students alleging sexual harassment, 228 and lawsuits by tenure-track faculty fired for sexual harassment.229 More generally, many types of databases are now available for integrated, data-driven law enforcement; any dataset documenting and recording misconduct or dispute can be a relevant source of information. First, databases currently used and maintained by law enforcement agencies can prove helpful in identifying patterns of unethicality.230 Existing law enforcement datasets have grown increasingly rich and detailed,231 now offering data points measured in the trillions even before 223 Andrew G. Ferguson, Big Data and Predictive Reasonable Suspicion, 63(2) U. PA. L. REV. 327, 353 (2015). 224 Sarah Brayne, Big Data Surveillance: The Case of Policing, 82(5) L. & SOC’Y REV. 977, 992 (2017) (describing the move towards a lower threshold for inclusion in law enforcement databases as part of the shift to big data law enforcement). 225 Nancy Chi Cantalupo & William C. Kidder, A Systematic Look at a Serial Problem: Sexual Harassment of Students by University Faculty, UTAH L. REV. (forthcoming 2018). 226 Id. at 25. 227 Id. at 36. 228 Id. 229 Id. at 48. 230 James Jacobs & Tamara Crepet, The Expanding Scope, Use, and Availability of Criminal Records, 11 N.Y.U. J. LEGIS. & PUB. POL’Y 177, 181-82 (2008) (describing recent developments in the accessibility variety of data offered by existing law enforcement datasets). 231 Lior J. Strahilevitz, Reputation Nation: Law in an Era of Ubiquitous Personal Information, 102 NW. U. L. REV. 1667, 1720 (2008) (describing the richness and variety of Big Data & Bounded Ethicality 1/1/2019 the move to integrated datasets.232 These sources include datasets compiled by law enforcement agencies themselves,233 as well as databases complied by private companies to be used by law enforcement agencies.234 Analyzed correctly, this currently available data can prove crucial in identifying and characterizing the exact details of situations that breed unethical conduct. Second, datasets maintained by regulators or consumer protection agencies may also prove useful. For example, in the context of financial regulation, the Securities and Exchange Commission, the Office of the Comptroller of the Currency, and other regulatory bodies hold extensive records on unethical behavior, as do the Federal Trade Commission’s Bureau of Consumer Protection and other bodies dealing with consumer complaints. Mining the information currently held by those institutions will enable us to characterize the types of situations under which unethical conduct seems to flourish. After such situations are identified, they can be targeted by regulatory measures that either encourage moral deliberation or hold accountable those responsible for creating these situations. Third, private commercial actors may also maintain databases that could prove useful for our purposes. Thus, financial institutions keep extensive records, directly and indirectly documenting the actions, preferences and behavior of both employees and consumers.235 Similar datasets are maintained and used by retailers, pharmaceutical companies, and technology firms. 236 Some private companies, especially in financial government held databases). 232 See Nicolas P. Terry, Protecting Patient Privacy in the Age of Big Data, 81 UMKC L. REV. 385, 389 (2012) (describing the massive volume of data held in individual datasets). 233 See Fred H. Cate, Government Data Mining: The Need for a Legal Framework, 43 HARV. C.R.-C.L. L. REV. 435, 442-3 (2008) (describing extensive databases maintained by the FBI in its Criminal Justice Information Services Division [CJISD]). 234 See Chris Jay Hoofnagle, Big Brother’s Little Helpers: How ChoicePoint and Other Commercial Data Brokers Collect and Package Your Data for Law Enforcement, 29 N.C. J. INT’L L. & COM. REG. 595, 600–7 (2004) (describing the types of data compiled by different information firms for use by law enforcers). These practices have also raised concerns; see Joshua L. Simmons, Note, Buying You: The Government’s Use of Fourth- Parties to Launder Data About ‘The People,’ 2009 COLUM. BUS. L. REV. 950, 951–52, 990-99 (arguing that the government is being opportunistic in turning to private companies that can provide information that government agencies are restricted from collecting themselves). 235 Janet Dean Gertz, The Purloined Personality: Consumer Profiling in Financial Services, 39 SAN DIEGO L. REV. 943, 944–5 (2002) (highlighting the amount of information that financial transaction data exposes). 236 Candice L. Kline, Security Theater and Database-Driven Information Markets: A Case for an Omnibus U.S. Data Privacy Statute, 39 U. TOL. L. REV. 443, 447 (2008); Sam Kamin, The Private Is Public: The Relevance of Private Actors in Defining the Fourth Amendment, 46 B.C. L. REV. 83, 125–27 (2004) (discussing databases that retailers 1/1/2019 Feldman & Kaplan markets, are already implementing situational regulation of their employees. For example, JP Morgan Chase provides ethical reminders to employees, warning them when they are approaching the limits of legitimate business practices. Such warnings are based on “predictive monitoring” algorithms and attempt to prevent wrongdoing before it occurs.237 This type of mechanism, which is based on big data analysis, is now being adopted by other financial institutions.238 The information collected by JP Morgan Chase and similar institutions can be used as another source of information for a larger big data regulatory scheme, barring proprietary considerations. Fourth, valuable information about disputes can be gleaned from online dispute resolution (ODR) records. Since the 1990s, online markets have developed their own dispute resolution systems operating alongside, and sometimes instead of, more traditional systems of adjudication.239 These new systems manage an enormous volume of disputes, which are usually fully documented online.240 Tapping into these datasets would enable an analysis of those situations that typically give rise to legal disputes following some type of misconduct. Relevant datasets include those maintained by eBay's Resolution Center, Amazon, or any other major online sellers. The analysis of the information might show which types of products or services are more likely to generate disputes. From a legal perspective, there is currently no difference between misrepresentation in selling a used car or in selling a used toy. However, from a behavioral perspective, such differences can be expected to exist, and some transactions, for example, those with more ambiguous definitions of what needs to be revealed to the buyers, are likely to lead sellers to more readily engage in motivated reasoning and justify or ignore unethical behavior. The use of big data analysis can reveal such trends, which will allow for the deployment of appropriate regulatory tools. Fifth, general use databases can also contain much detailed information about situational wrongdoing and circumstances that lead to unethicality.241 compile in order to store consumer information). 237 Haugh, supra note 47, at 712, 736. 238 Credit Suisse is developing a compliance program with Palantir Technologies, a Silicon Valley tech company focused on data analysis for police and intelligence services; Jeffrey Vogeli, Credit Suisse, CIA-Funded Palantir to Target Rogue Bankers, BLOOMBERG (Mar. 22, 2016), funded-palantir-build-joint-compliance-firm. 239 Ayelet Sela, The Effect of Online Technologies on Dispute Resolution System Design: Antecedents, Current Trends and Future Directions, 21 LEWIS & CLARK L. REV. 633, 673 (2017). 240 Id. at 636. 241 See Nicolas P. Terry, Protecting Patient Privacy in the Age of Big Data, 81 UMKC L. REV. 385, 389 (2012) (explaining that big data increasingly comes from less structured sources such as social network communications, web searches, and smartphone use Big Data & Bounded Ethicality 1/1/2019 For example, Google search records have proven valuable in uncovering patterns of human choice and behavior in a variety of contexts.242 Online behavior patterns can be used to determine those settings that tend to encourage dishonesty. E. The Strength of Data-Driven Interventions A final relevant feature of data-driven law enforcement is its increased effectiveness. Regulatory interventions based on big data analysis are recognized as more potent, since their use is much better guided than traditional enforcement steps.243 This can be crucial in improving the effectiveness of ethical nudges, and facilitate a much necessary advance in regulating bounded ethicality. As mentioned above, improving moral deliberation is a particularly tricky task. Traditional nudges are aimed at helping people make better decisions for themselves. As such, nudges are aligned with the interests of the individuals being nudged, and are therefore easy to accept. Conversely, ethical nudges are designed to make people ignore their own self-interest or consider the interests of others.244 Therefore, people encountering ethical nudges might object to or reject them. The same mechanisms of bounded ethicality that led to misconduct in the first place can now be used as people ignore ethical nudges and their messages. For this reason, it is crucial that ethical nudges be made as effective as possible. Using big data analysis has been proven highly effective in achieving this goal. IV. REORIENTING BIG DATA LAW ENFORCEMENT Whatever we might think of it, big data law enforcement is already here, and is here to stay.245 The practice of using big data is already deeply entrenched in existing law enforcement procedures.246 To give one example records). 242 SETH STEPHENS-DAVIDOWITZ, EVERYBODY LIES: BIG DATA, NEW DATA, AND WHAT THE INTERNET CAN TELL US ABOUT WHO WE REALLY ARE (2017); see also VIKTOR MAYER-SCHÖNBERGER & KENNETH CUKIER, BIG DATA: A REVOLUTION THAT WILL TRANSFORM HOW WE LIVE, WORK, AND THINK 2 (2013) (describing Google’s ability to track the spread of the H1N1 flu in 2009 based on people’s internet searches). 243 Sarah Brayne, Big Data Surveillance: The Case of Policing, 82(5) L. & SOC’Y REV. 977, 981–2 (2017). 244 FELDMAN, supra note 2, at 198–9. 245 Andrew G. Ferguson, Big Data and Predictive Reasonable Suspicion, 63(2) U. PA. L. REV. 327, 351 (2015) (reviewing current use of big data by law enforcement agencies). 246 See BRAD BROWN, CHARLES ROXBURGH, JACQUES BUGHIN, JAMES MANYIKA, MICHAEL CHUI & RICHARD DOBBS, BIG DATA: THE NEXT FRONTIER FOR INNOVATION, COMPETITION, AND PRODUCTIVITY 85 (2011) (describing police practices in using 1/1/2019 Feldman & Kaplan of this trend, consider the case of Palantir Technologies, a private software company specializing in big data analytics. Palantir, founded in 2004, is just one of the major big data platforms currently used by law enforcers in the United States. Palantir customers include the Central Intelligence Agency (CIA), Federal Bureau of Investigation (FBI), National Security Agency (NSA), United States Department of Homeland Security (DHS), United States Immigration and Costumes Enforcement (ICE), as well as police departments in major American cities such as New York and Los Angeles.247 This prevalence of data-driven law enforcement has raised important legitimacy concerns. Mainly, commentators have voiced objections to this emerging form of law enforcement based on privacy and autonomy concerns,248 arguing that law enforcement based on big data may violate citizens’ Fourth Amendment rights.249 We believe that these objections to the use of big data in law enforcement are well-reasoned, pointing out the very real possibility that big data analytics grant too much power to governments, power that will eventually be abused. Scholars have similarly commented that the use of big data analysis by policy makers can perpetuate existing discriminatory patterns by mimicking therm.250 We therefore believe that this trend, which currently seems inevitable, must be accompanied by the development of significant safeguards, designed to prevent abuse. In this framework, we argue for a reorientation of current practices of big data law enforcement, and a rethinking of its goals and operations. In particular, we show that if big data law enforcement makes the regulation of bounded ethicality its main goal, as we propose, this can help mitigate some of the legitimate concerns regarding the use of big data analytics by law enforcers. This is true for two main reasons. First, to overcome bounded cellphone information). 247 Kim A. Taipale, Data Mining and Domestic Security: Connecting the Dots to Make Sense of Data, 5 COLUM. SCI. & TECH. L. REV. 1, 14–15 (2003) (showing that law enforcement agencies are already utilizing big data analysis in a variety of contexts, and arguing it would be unrealistic to expect these practices to stop). 248 Daniel J. Solove, Digital Dossiers and the Dissipation of Fourth Amendment Privacy, 75 S. CAL. L. REV. 1083, 1089 (2002) (highlighting the risk to privacy in a world in which personal data is increasingly held by third parties, and not by the individuals who own this data). 249 Andrew G. Ferguson, Big Data and Predictive Reasonable Suspicion, 63(2) U. PA. L. REV. 327, 398 (2015) (evaluating the constitutionality of the use of big data analytics as a basis for police searches and seizures). 250 Solon Barocas & Andrew D. Selbst, Big Data’s Disparate Impact, 104 CAL. L. REV. 671, 671–2 (2016) (showing that the quality of algorithmic decision-making critically depends on the data on which it operates; if the data reflects prior biases and prejudices by policy makers, those biases will be reflected in the results of the algorithmic analysis). Big Data & Bounded Ethicality 1/1/2019 ethicality, governments do not need to gather information at the personal level. Unlike the use of big data in other contexts, such as the prevention of serious crime, the goal of government intervention is not to single out exceptionally malevolent individuals, but to identify the conditions that lead to ethical biases by ordinary people. This means that privacy concerns are somewhat less alarming in this context, as information need not be attached to specific individuals. Similarly, concerns regarding the perpetuation of prejudice and discriminatory practices is less troubling, again because big data analysis is used to produce situational predictions rather than personalized ones. Second, to regulate bounded ethicality, governments should make greater use of softer regulatory tools, designed not to punish, but to assist potential perpetrators engage in more candid ethical reflection. Since the regulatory intervention is significantly gentler, concerns regarding the harms caused to citizens through state-initiated aggression or violence are somewhat mitigated. Importantly, these points are not to be taken to mean that data-driven law enforcement does not raise significant concerns. We only argue that these concerns are somewhat mitigated in the framework we propose aimed at regulating bounded ethicality, and that current practices of digital law enforcement must be reoriented to address these concerns. We first present the existing personalized law approach to big data, and then continue by presenting the advantages of our proposed situation-based approach. A. The Existing Personalized Law Approach Big data law enforcement is currently closely tied to the concept of personalized law,251 which involves more nuanced legal responses tailored to the personal characteristics of specific individuals. The current thinking is that the natural development of big data analysis, and law enforcement generally, is towards a more personalized future, where enforcement efforts will be directed towards specific individuals.252 The personalized law approach therefore upends the fundamental feature of the legal system: that the law treats all individuals equally and thus aspires to be objective and impersonal.253 Traditionally, many legal 251 Andrew G. Ferguson, Big Data and Predictive Reasonable Suspicion, 63(2) U. PA. L. REV. 327, 351 (2015) (providing a warning regarding the individual aspect of big data policing). 252 Id. at 365 (“To solve crimes, law enforcement must not only collect information, but also identify and link individuals to their accumulated data. In short, data must be connected with identifiable human beings”). 253 Ariel Porat & Lior J. Strahilevitz, Personalizing Default Rules and Disclosure with 1/1/2019 Feldman & Kaplan doctrines are based on objective standards of behavior and set general criteria against which to measure each individual's conduct. For instance, in tort law, the standard of the reasonable person sets a uniform requirement for appropriate care and caution.254 Similarly, contract default rules seek to recreate the presumed intentions of the typical contracting party. These “one size fit all” standards structure the law according to some general and objective point of reference.255 Recently, scholars have started to question this basic framework and to call for the more personalized application of legal standards.256 They argue for the use of big data analysis to set legal standards that are tailored more precisely to each specific individual. Thus, the actions of a tortfeasor should not be measured against the general and objective standard of the reasonable person” but rather against that of a reasonable self. That is, the court should be asked to verify whether or not the tortfeasor behaved in a way that can be considered reasonable for him or her, considering all personal abilities and limitations.257 Scholars have also pointed out that this approach is not entirely alien to existing legal practices and, in fact, has always existed alongside the traditional position based on an objective and impersonal approach.258 Given the much greater availability and verifiability of information about individuals today, these scholars advocate towards more finely calibrated tilt that subjectivity.259 the balance should now The personalized law approach uses big data to discern individual characteristics and then to apply a more nuanced type of law tailored to the needs and abilities of specific individuals.260 Research studies have shown that personality traits can be discerned from the analysis of readily available Big Data, 112 MICH. L. REV. 1417, 1418 (2014). 254 O.W. HOLMES, JR., THE COMMON LAW 108 (1881); DAN B. DOBBS, THE LAW OF TORTS § 117, at 277 (1st ed. 2000). 255 Porat & Strahilevitz, supra note 253, at 1418. 256 Cass R. Sunstein, Deciding by Default, 162 U. PA. L. REV. 1, 7–10, 56–57 (2013); Ian Ayres, Preliminary Thoughts on Optimal Tailoring of Contractual Rules, 3 S. CAL. INTERDISC. L.J. 1, 4 & n.15 (1993) (generally discussing the appropriate specificity of contractual default rules); George S. Geis, An Experiment in the Optimal Precision of Contract Default Rules, 80 TUL. L. REV. 1109, 1114–15, 1129–59 (2006). In many ways, this literature is a direct continuation of the scholarship on contractual default rules, see Ian Ayres & Robert Gertner, Filling Gaps in Incomplete Contracts: An Economic Theory of Default Rules, 99 YALE L.J. 87, 89–95, 97–98, 115–18 (1989). 257 Omri Ben-Shahar & Ariel Porat, Personalizing Negligence Law, 91 N.Y. L. REV. 627, 630–1 (2016) (suggesting that courts can utilize big data information to better tailor personalized standards of care for specific tortfeasors and tort victims). 258 Id. at 629–30. 259 Id. at 628, 636. 260 Porat & Strahilevitz, supra note 253, at 1419. Big Data & Bounded Ethicality 1/1/2019 information, such as people's smartphone usage patterns or shopping history.261 On the basis of this information, regulators can construct person- level psychological profiles and subsequently apply legal standards that would offer a good fit at the individual level.262 Thus, regulators can identify individuals’ psychological profiles in order to predict their tendencies towards bounded ethicality and target specific enforcement efforts accordingly. Police forces throughout the United States are already employing big data analytics in order to better identify suspects.263 In criticizing this literature, we suggest that the personalized law approach suffers not only from legitimacy concerns due to its costs with respect to privacy and equality, but that it is also poorly calibrated for the regulation of unethical behavior as a practical matter. The main reason for this is the insufficiency of interpersonal variation as a predictor of unethicality relative to the proven importance of situational factors. 1. Interpersonal Variation and Bounded Ethicality This section provides background for our critique by describing existing tools used to predict unethicality based on interpersonal variation. Such a prediction strategy is based on the idea that different people are not equally likely to engage in unethical conduct, and that such tendencies can be observed by researchers and regulators at the personal level. Several existing research paradigms are used to identify people who are supposedly more likely to engage in unethical behavior. For example, researchers have found some interpersonal variation in individuals' propensity to morally disengage.264 Celia Moore created a typology of individuals based on the likelihood of their engaging in unethical conduct in the workplace. One of the key elements in Moore’s 261 Id. at 1438. 262 Id. at 1439. 263 Elizabeth E. Joh, The New Surveillance Discretion: Automated Suspicion, Big Data, and Policing, 10(1) HARV. L. & POL'Y REV. 15, 16 (2016) (describing police use of big data tool to identify suspects). 264 Celia Moore, Moral disengagement, 6 CURRENT OPINION IN PSYCHOL. 199 (2015) (reviewing the main points of moral disengagement theory); Celia Moore, James R. Detert, Linda K. Treviño, Vicki L. Baker & David M. Mayer, Why Employees do Bad Things: Moral Disengagement and Unethical Organizational Behavior, 65(1) PERSONNEL PSYCHOL. 1 (2012) (studying the propensity to moral disengage as predicting unethical in Processes of organizational behavior); Celia Moore, Moral Disengagement Organizational Corruption, 80 J. BUS. ETHICS 129 (2008) (Showing that moral disengagement can contribute to corruption within organizations through dampening individuals' moral awareness). 1/1/2019 Feldman & Kaplan model is an individual’s propensity to make excuses to justify harming others. This typology is based on Bandura’s well-known concept of moral disengagement.265 Similarly, Reynolds et al. demonstrate a moderate correlation between moral disengagement as and Machiavellianism and cognitive moral development.266 traits such A related concept, moral firmness, measures people’s willingness to tolerate and justify dishonesty.267 Shalvi & Leiser have found some variance among individuals in their levels of moral firmness, depending on, among other things, their upbringing and social background.268 Similarly, Aquino’s moral identity scale, and the various studies based on it, have found that an individual’s likelihood of behaving in an unethical manner, even implicitly, varies based on the degree to which morality is a central component of his or her identity.269 Another related measure is the rule orientation scale, measuring people’s willingness to violate legal rules. This concept aims to capture the extent to which one is willing to recognize and construct exceptions to legal rules, as opposed to viewing them as rigid categorical obligations.270 Personal tendencies towards bounded ethicality might also be discerned through measures relating to individuals’ inclination to rely on intuitive or implicit judgement. For example, studies on the implicit association test (IAT) measure people’s tendency to make intuitive connections between unrelated concepts. While the IAT was not originally designed to predict unethicality, it has since been used for this purpose. For example, the IAT has become the gold standard for measuring employment discrimination, such as determining whether employers associate ethnicity, for example, with qualifications for employment. This line of research suggests variations among people in terms of unethical tendencies.271 Similarly, 265 Bandura, supra note 54. 266 Scott J. Reynolds, Carolyn T. Dang, Kai Chi Yam & Keith Leavitt, The role of moral knowledge in everyday immorality: What does it matter if I know what is right?, 123 ORGANIZATIONAL BEHAVIOR & HUMAN DECISION PROCESSES 124, 126 (2014). 267 Shaul Shalvi & David Leiser, Moral Firmness, 93 J. ECON. BEHAVIOR & ORG. 400, 400–1 (2013). 268 Id. 269 Karl Aquino, Dan Freeman, Americus Reed II, Vivien K. G. Lim & Will Felps, Testing A Social-Cognitive Model of Moral Behavior: The Interactive Influence of Situations and Moral Identity Centrality, 97(1) J. PERSONALITY & SOC. PSYCHOL. 123, 138–9 (2009). 270 Adam Fine, Benjamin Van Rooij, Yuval Feldman, Shaul Shalvi, Eline Scheper, Margarita Leib & Elizabeth Cauffman, Rule Orientation and Behavior: Development and Validation of a Scale Measuring Individual Acceptance of Rule Violation, 22(3) PSYCHOL. PUB. POL'Y & L. 314, 314–5 (2016). 271 Anthony G. Greenwald, Debbie E. McGhee & Jordan L. K. Schwartz, Measuring Individual Differences in Implicit Cognition: The Implicit Association Test, 74(6) J. Big Data & Bounded Ethicality 1/1/2019 research in the area of judicial decision-making has shown that the IAT score of different judges predicted their discriminatory behavior against black defendants.272 Frederick’s cognitive reflection test (CRT) is another measure that may prove valuable for predicting unethicality.273 This scale rates individuals based on the likelihood that they will use System 2 thinking to overcome System 1 reasoning. Studies using this scale have focused on the correlation between an individual’s CRT grade and other behavioral measures.274 2. The Inadequacy of Personality Traits as Predictors of Unethicality Despite this rich literature on variations among people regarding their likelihood of engaging in unethical behavior, interpersonal variation is not dramatic or stable enough to allow differentiation in legal treatment. In fact, as discussed earlier, behavioral ethics that an overwhelming percentage of individuals will behave unethically in some situations.275 Thus, in certain circumstances, personality traits barely contribute to differences in behavior, so interpersonal variance is largely unhelpful in focusing regulation efforts. Similarly, there is not enough research to indicate that any of the earlier mentioned scales consistently identify what types of people are likely to engage in unethical conduct in the real world. findings indicate Furthermore, even if people vary in their propensity for engaging in is unclear that such differences are readily unethical behavior, discernable, even with the use of big data analysis. For instance, regulators may not be able to measure an individual’s IAT score or CRT grade, without having that individual sit through a specifically designed test in a it PERSONALITY & SOC. PSYCHOL. 1464, 1464–5 (1998); Anthony G. Greenwald, Eric L. Uhlmann, Mahzarin R. Banaji, Understanding and Using the Implicit Association Test: III. Meta-Analysis of Predictive Validity, 97(1) J. PERSONALITY & SOC. PSYCHOL. 17, 41 (2009). 272 Jeffrey J. Rachlinski, Sheri Lynn Johnson, Andrew J. Wistrich & Chris Guthrie, Does Unconscious Racial Bias Affect Trial Judges? 84(3) NOTRE DAME L. REV. 1195, 1232 (2009). 273 Shane Frederick, Cognitive Reflection and Decision Making, 19(4) J. ECON. PERSP. 25 (2005); Maggie E. Toplak, Richard F. West & Keith E. Stanovich, The Cognitive Reflection Test as a Predictor of Performance on Heuristics-And-Biases Tasks, 39(7) MEMORY & COGNITION 1275, 1275–6 (2011) (studying the correlation between CRT scores, cognitive ability, and the ability to successfully use heuristics and overcome biased thinking). 274 Toplak, West & Stanovich, supra note 273; Joseph M. Paxton, Leo Ungar & Joshua D. Greene, Reflection and Reasoning in Moral Judgment, 36(1) COGNITIVE SCI. 163 (2012) (studying the effects of opportunities for reflection on moral judgment). 275 ARIELY & JONES, supra note 8. 1/1/2019 Feldman & Kaplan lab setting. Similarly, policy makers may lack a reliable method for observing people’s rule orientation scale, degree of moral firmness, moral identity or propensity to morally disengage. Personality prediction may be somewhat helpful in legal contexts that focus on extreme behaviors, such as determining an individual’s level of dangerousness in the criminal law context.276 In cases involving extremely threatening behaviors, prediction might be possible based on individual variance, because the focus is on people who rank very high on many of the relevant scales related to deviant behavior.277 In contrast, more common unethical acts can be committed by individuals closer to the middle of the curve in terms of personal propensities.278 Even with the use of big data analysis, it is not clear that we can know, prior to a given transaction, whether or not individual personality traits would matter enough to justify targeted regulation. Thus, we disagree with the approach advocated by Porat & Strahilevitz, who call for reliance on the Big Five personality traits theory in the creation of personalized legal treatment.279 Applying a personalized approach to target unethicality is also problematic because it may fail to capture temporal variance. Behavioral ethics research suggests that past behavior may not adequately predict future conduct because of the phenomenon of moral licensing, in which people use their past good deeds to excuse later misconduct.280 Monin & Miller found that participants in their experiments who believed that they had previously established their moral credentials (in this case, a lack of prejudice) felt empowered to subsequently express views that violated moral norms.281 In essence, individuals who consider themselves to be good based on their past behavior may permit themselves to bend the rules and thus be more likely to make unethical decisions as time passes.282 These findings are contrary to the traditional view, which holds that those who behaved badly in the past are more likely to do so in the future. Because 276 Scott, P. D., Assessing Dangerousness in Criminals, 131(2) BRITISH J. PSYCHIATRY 127 (1977); Malcolm M. Feeley & Jonathan Simon, Actuarial Justice: The Emerging New Criminal Law, in THE FUTURES OF CRIMINOLOGY 173, 173–5 (David Nelken ed., 1994). 277 Ronald Blackburn, On Moral Judgements and Personality Disorders: The Myth of Psychopathic Personality Revisited, 153(5) BRITISH J. PSYCHIATRY, 505, 507 (1988). 278 FELDMAN, supra note 2, at 32. 279 Porat & Strahilevitz, supra note 253, at 1418. 280 Daniel A. Effron & Benoît Monin, Letting People Off the Hook: When Do Good Deeds Excuse Transgressions?, 36 PERSONALITY & SOC. PSYCHOL. BULLETIN 1618 (2010) (studying differences between types of past good deeds in their propensity to allow future misconduct). 281 Benoît Monin & Dale T. Miller, Moral Credentials and the Expression of Prejudice, 81(1) J. PERSONALITY & SOC. PSYCHOL. 33, 43 (2001). 282 Shaul Shalvi, Ori Eldar & Yoella Bereby-Meyer, Honesty Requires Time (and Lack of Justifications), 23(10) PSYCHOL. SCI. 1264, 1264–7 (2012). Big Data & Bounded Ethicality 1/1/2019 individuals’ past behavior is not always a good indicator of their future conduct, a personalized law approach to bounded ethicality may not be useful. Finally, as mentioned above, the use of personal data as a predictor of unethicality is highly abrasive, critically violating individual privacy and autonomy norms. When state officials utilize big data analysis to police individual behavior, they not only misappropriate private information, but also undermine autonomy as they restrict if not eliminate the meaning of individuals’ choice and their ability to determine their own personal fate, regardless of the statistical risk they happen to represent. 3. Personalizing Law Based on Demographic Information In addition to personalized information, law enforcers currently use demographic data to guide enforcement efforts.283 We argue this practice represents an inappropriate use of big data analytics. First, research findings are mixed on the usefulness of demographic data as a general predictor of unethicality. Tenbrunsel and colleagues suggest that demographic factors lack significant predictive value. They found no or only a small correlation between demographic factors such as gender or education level and the propensity to commit wrongdoing.284 Other researchers have found a more consistent relationship between demographic factors and misconduct.285 Studies on the relationship between culture and unethicality have also produced conflicting findings. For example, a previously reported compliance gap between Brazilians and Americans was not found in later studies.286 Tenbrunsel and colleagues also have reported mixed findings on the relationship between gender and unethicality.287 On the whole, research suggests that demographic data are not likely to be useful, at least not in a consistent way. More raises constitutional concerns and is objectionable on moral grounds. Targeted the use of demographic importantly, information 283 Kate Crawford & Jason Schultz, Big Data and Due Process: Toward a Framework to Redress Predictive Privacy Harms, 55 B.C. L. REV. 93, 104 (2014). 284 Ann E. Tenbrunsel & Kristin Smith‐Crowe, Ethical Decision Making: Where We’ve Been and Where We’re Going, 2(1) ACADEMY OF MANAGEMENT ANNALS 545, 607 (2008). 285 Simon Gächter & Jonathan F. Schulz, Intrinsic Honesty and the Prevalence of Rule Violations Across Societies, 531(7595) NATURE 496 (2016) (using samples from different time periods, the authors discuss causality between institutions and individual honesty). 286 Jonathan Haidt, Silvia H. Koller & Maria G. Dias, Affect, Culture, and Morality, Or Is It Wrong To Eat Your Dog?, 65(4) J. PERSONALITY & SOC. PSYCHOL. 613, 6123, 621–3 (1993). 287 Tenbrunsel & Smith‐Crowe, supra note 284, at 608. 1/1/2019 Feldman & Kaplan regulation based on demographic information should be considered a type of profiling and therefore prohibited.288 Similarly, the use of personal or demographic information in law enforcement perpetuates existing biases, and therefore reflects not the precursors of wrongdoing, but the existing, often prejudiced, focus of law enforcement efforts.289 B. The Proposed Situational Law Paradigm Behavioral ethics research demonstrates that in many cases, unethicality is situation driven; it does not require any exceptional antisocial sentiment on the part of the perpetrator and ordinary people regularly participate in it. Thus, the aggregate result of experiments described by researchers is that unethicality is not limited to any specific group of people.290 However, people do not always act unethically; they do so only when they can find ways to justify, excuse or ignore their conduct. In practical terms, bounded ethicality typically originates with the existence of a situational moral blind spot. 1. The Mechanics of Situational Regulation Moral blind spots are not always operative, and their presence depends on a host of factors that can converge, creating situations in which individuals’ moral judgement is more easily impaired. Thus, some behavioral ethics experiments have identified situations in which up to 80 percent of people were found to lie.291 More significantly, behavioral ethics research shows that unethicality is highly predictable based on situational factors.292 Therefore, the best way to identify focal points of unethicality is by targeting suspect situations, rather than suspect individuals. Focusing on the typical transgressor across different situations rather than on individual variation, which is based on the past behavior of individuals, offers several advantages.293 Because individuals have a limited ability to monitor their own behavior, situational factors play a larger role in prompting them to commit wrongdoing than is traditionally assumed in 288 Samuel R. Gross & Debra Livingston, Racial Profiling under Attack, 102 COLUM. L. REV. 1413, 1438 (2002). 289 Barocas & Selbst supra note 250 at 672; See also Devah Pager & Hana Shepherd, The Sociology of Discrimination: Racial Discrimination in Employment, Housing, Credit, and Consumer Markets, 34 ANN. REV. SOC. 181, 182 (2008) (describing current discriminatory practices and pointing out their prevalence even in the post-civil-rights era). 290 ARIELY & JONES, supra note 8. 291 Gerlach et al, supra note 132. 292 Dana et al, supra note 30. 293 Gino, supra note 1; BAZERMAN & TENBRUNSEL, supra note 35. Big Data & Bounded Ethicality 1/1/2019 mainstream legal scholarship. Much research has been done on the connection between bounded ethicality and the situations in which it is prevalent. In their discussion of the situational factors affecting moral awareness, Tenbrunsel & Smith-Crowe conclude that an ethical infrastructure, based on cultural and institutional factors, is related to the level of moral awareness much more closely than are individual factors.294 In this vein, Tenbrunsel & Messick295 argue that the design of formal and informal systems, as well as the general organizational climate, is responsible for much unethical behavior.296 Thus, to prevent and reduce unethicality, regulators need to know more about those situations that tend to trigger unethical behavior. For example, regulators could try to identify at what times during the day people are more likely to behave unethically.297 Other factors include the identity of the parties to a specific transaction, the nature of the goods or services provided, the relationship between the parties, and whether either of them is a repeat or a one-time player. More generally, the more information we have about the situational causes of unethicality, the more likely it becomes that targeted situational regulation will effectively reduce it. The use of big data can prove invaluable for this purpose. We suggest that big data analytics be used to identify situational wrongdoing and then design tailored enforcement solutions to combat it, based on predictions related to the typical transgressor in those situations. Note that the nature of the information to be analyzed here is markedly different from that required by the personalized law approach. The latter approach requires information that can be explicitly attributed to a specific individual. Thus, a regulator may use an individual’s smartphone use history to build a personal profile, which would then be used to construct a standard of behavior specifically tailored for that individual.298 This approach obviously raises significant privacy concerns. In contrast, a situational regulatory approach requires information relating to situations and the typical transgressor that appears in them, rather than information regarding individuals. Regulators would need to know what situations lead to an exceptionally high incidence of unethical behaviors, regardless of the 294 Tenbrunsel & Smith‐Crowe, supra note 284, at 545–6. 295 Tenbrunsel & Messick, supra note 54, at 223. 296 Based on Bandura, supra note 54. Ethical fading refers to individuals' ability to unconsciously disregard the ethical consequences of their choices. The use of euphemisms supports this tendency as it helps shield actors from the unpleasantness associated with harming others. 297 Maryam Kouchaki & Isaac H. Smith, The Morning Morality Effect: The Influence of Time of Day on Unethical Behavior, 24 PSYCHOL. SCI. 95 (2014) (studying ethical depletion throughout the hours of the day). 298 Porat & Strahilevitz, supra note 253, at 1438. 1/1/2019 Feldman & Kaplan identity of the specific wrongdoers. Thus, they would not gather information on specific individuals, but instead would generate data on an aggregate basis to construct, for example, an occupational profile that provides insight into the behavior of people across certain situations where unethical conduct might be on the rise. 2. The Advantages of Situational Regulation There are many benefits to tailoring regulation based on situational factors, instead of personal ones. As suggested earlier, a focus on individuals is unlikely to significantly improve the predictability of unethicality, because such a large proportion of people engage in such misconduct in certain circumstances.299 Conversely, behavioral ethics research shows that situational indicators are the strongest predictors of unethicality.300 Second, the focus on situations can help prevent ethical numbing.301 Using ethical alerts only when they are most relevant is helpful in their retaining their force. If regulators know which situations call for misconduct, they can address problems in a targeted manner and trigger moral deliberation only when it will be most impactful. This is a significant advantage of situational differentiation over personal differentiation. If regulation were to be targeted towards specific individuals, this would result in those individuals encountering ethical alerts very frequently, thereby diluting the effectiveness of such reminders and defeating the purpose of the regulatory intervention. Third, when focusing on the individual, we are faced with many contingency problems in every situation where more than one person is involved, which occurs in most commercial contexts. Hence, finding the best regulatory tool to deal with an individual based on his or her past behavior would be problematic. In addition, individual behavior is also contingent on its interaction with the situation, which also limits the accuracy of individual-based prediction. Fourth, there are many more data points on situations than on individuals, particularly given the personalized law literature. Even the analysis of a very specific type of transaction is likely to generate multiple data points on each situation, greatly increasing the likelihood that prediction will be accurate. the evidence-based approach of 299 Gerlach et al, supra note 132. 300 BAZERMAN & TENBRUNSEL, supra note 35, at 1–3 (highlighting the predictability of unethicality based on situational factors). 301 Tenbrunsel & Messick, supra note 54, at 228 (explaining the sources of ethical numbing). Big Data & Bounded Ethicality 1/1/2019 Fifth, the focus on the situation reduces the saliency of distributive justice concerns, because it is the context, and not the people who are being treated differently. Recommended policy changes will then be based on differences among situations and not among individuals. This is a crucial step towards mitigating the concerns regarding the discriminatory effects of data-driven law enforcement.302 If data-driven predictions are focused not on individuals but on situations, there is less of a concern that data analysis will incorporate or perpetuate any prejudicial and discriminatory practices. Sixth, the focus on the situation, not the individual, mitigates privacy concerns associated with the use of big data analytics. Privacy issues arising in this context are typically related to the ability to gather private information about specific individuals, rather than to gathering aggregate statistics, which provide data regarding the behavior of many unidentified individuals in a particular situation.303 CONCLUSION This paper reconceptualises current practices of big data law enforcement and offers a novel framework for regulating bounded ethicality. By utilizing big data analytics, policy makers can predict unethicality and then deploy targeted regulatory responses in real time in order to improve ethical deliberation by potential perpetrators. The use of targeted ethical reminders can improve ethical decision-making, without running the risk of creating ethical numbing and over bombarding people with meaningless and random ethical messages. Big data analysis can also help tailor the most appropriate regulatory response to each specific case, and match it to the specific bias that is creating the opportunity for unethical conduct. This paper identifies the advantages of using big data analytics as a platform for curbing bounded ethicality, and also recommends important alterations in the way big data is currently used by law enforcers. Thus, we advocate a shift in the use of big data from a personalized to a situational approach. This move can render the use of big data more effective, in light of behavioral ethics findings that suggest that problematic situations, or moral blind spots, are often stronger predictors of unethicality are interpersonal variations. Fortunately, this suggestion also represents a welcome change in terms of the legitimacy of the use of big data analytics by law enforcers. Thus, while the current personalized approach raises deep concerns regarding citizens’ privacy and the perpetuation of discriminatory 302 Barocas & Selbst supra note, 250 at 672. 303 Kate Crawford & Jason Schultz, Big Data and Due Process: Toward a Framework to Redress Predictive Privacy Harms, 55 B.C. L. REV. 93, 94 (2014). 1/1/2019 Feldman & Kaplan practices, our proposed situational approach largely avoids these problems, as it does not require individualization of legal standards or a personalized focus of law enforcement efforts.